[{"authors":null,"categories":null,"content":"I study the genes of malaria parasites. I am interested in developing the tools needed to provide a better systems-level understanding of these parasites, with a focus on open-source methods for high-throughput culture.\n","date":1596240000,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1596240000,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"I study the genes of malaria parasites. I am interested in developing the tools needed to provide a better systems-level understanding of these parasites, with a focus on open-source methods for high-throughput culture.","tags":null,"title":"Theo Sanderson","type":"authors"},{"authors":[],"categories":null,"content":" Click on the Slides button above to view the built-in slides feature.   Slides can be added in a few ways:\n Create slides using Wowchemy\u0026rsquo;s Slides feature and link using slides parameter in the front matter of the talk file Upload an existing slide deck to static/ and link using url_slides parameter in the front matter of the talk file Embed your slides (e.g. Google Slides) or presentation video on this page using shortcodes.  Further event details, including page elements such as image galleries, can be added to the body of this page.\n","date":1906549200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1906549200,"objectID":"a8edef490afe42206247b6ac05657af0","permalink":"/talk/example-talk/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/example-talk/","section":"event","summary":"An example talk using Wowchemy's Markdown slides feature.","tags":[],"title":"Example Talk","type":"event"},{"authors":[],"categories":[],"content":"Somebody on Twitter asked me whether B.1.1.7 data from Florida was still compatible with a logistic increase\nIt\u0026rsquo;s amazing how simple this sort of thing is to look at with the Tidyverse and nicely formatted data SGTF data from Helix.\nlibrary(tidyverse) data = read_csv(url(\"https://raw.githubusercontent.com/myhelix/helix-covid19db/master/counts_by_state.csv\")) state_selection = (data %\u0026gt;% group_by(state) %\u0026gt;% summarise(total=sum(positive)) %\u0026gt;% filter(total\u0026gt;5000))$state data = data %\u0026gt;% mutate(percent_sgtf=all_SGTF/positive) %\u0026gt;% filter(state %in% state_selection) ggplot(data,aes(x=collection_date, y=percent_sgtf))+geom_point()+ stat_smooth(method = \"glm\", method.args = list(family = \"binomial\"), se = FALSE, fullrange=TRUE) +xlim(lubridate::ymd(\"2020-12-01\"),lubridate::ymd(\"2021-04-30\"))+labs(title=\"US SGTF\",x=\"Date\",y=\"Percent SGTF\")+facet_wrap(~state)+theme_bw()+scale_y_continuous(label=scales::percent)   There are lots of ways one could improve this, bringing in genome data and modelling uncertainty, but it provides a quick look at what\u0026rsquo;s happening.\n","date":1617099517,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1617099517,"objectID":"cfbd632326439b75949f87550a9936d2","permalink":"/post/2021-03-30-us-sgtf/","publishdate":"2021-03-30T10:18:37Z","relpermalink":"/post/2021-03-30-us-sgtf/","section":"post","summary":"Somebody on Twitter asked me whether B.1.1.7 data from Florida was still compatible with a logistic increase\nIt\u0026rsquo;s amazing how simple this sort of thing is to look at with the Tidyverse and nicely formatted data SGTF data from Helix.","tags":[],"title":"Five lines of R","type":"post"},{"authors":[],"categories":[],"content":"Summary: The ONS Coronavirus Infection Survey is an immensely valuable scientific project measuring prevalence of coronavirus in the community. However some useful data have been released only in graphical form which makes them hard to re-analyse. Here I describe how I went about turning one of these graphs back into data in R and briefly explore what it can tell us about SGTF in samples today.\n Background The ONS infection survey is an extremely valuable and well-conducted piece of work. As I discussed in a previous post sometimes the raw data outputs can be subject to different interpretations.\nOne challenge in interpreting this data in that post was that information on the relationship between the number of genes detected and the distribution of Ct values was not available. I resorted to examining this by calculating the Ct value in different regions, and relating this to the area\u0026rsquo;s mean Ct value. But what I really wanted was a line list containing Ct value data for each test, along with how many genes were detected (and ideally further information).\nI have since discovered that some of this data is available in a preprint published by the survey team in October 2020. Specifically, for me - the most valuable data is the graph below, which depicts individual tests with their Ct values, symptomatic status, and number of genes detected.\nUnfortunately this data is only presented graphically. But since the graphic is present in a vector format we may be able to get the data back out again without locating every point by hand. Here is how I went about this.\nknitr::opts_chunk$set(dev.args = list(png = list(type = \"cairo\"))) require(xml2) library(tidyverse) library(lubridate) library(rvest)   First we will read in the SVG file as XML and look at the straight lines - i.e.Â the axes, things like the axes and tick-lines.\ntheme_set(theme_classic()) doc \u0026lt;- read_xml(\"ons_scatterplot.svg\") %\u0026gt;% xml_ns_strip() lines \u0026lt;- xml_nodes(doc, \"line\") linesdf \u0026lt;- tibble(bind_rows(lapply(xml_attrs(lines), as.data.frame.list))) %\u0026gt;% mutate_at(c(\"x1\", \"x2\", \"y1\", \"y2\"), as.character) %\u0026gt;% mutate_at(c(\"x1\", \"x2\", \"y1\", \"y2\"), as.numeric) %\u0026gt;% mutate(y1 = -y1, y2 = -y2) %\u0026gt;% # y-axis is reversed in SVG - screen format is from top left mutate(length = sqrt((x2 - x1)^2 + (y2 - y1)^2))   Let\u0026rsquo;s try drawing this set of lines in ggplot. We\u0026rsquo;ll colour them in by their SVG class to see what class corresponds to which items of the plot.\nggplot(linesdf, aes(x = x1, xend = x2, y = y1, yend = y2, color = class)) + geom_segment()   OK, so st14 represents the black lines of the axis - lets extract those and mark them each as horizontal or vertical.\nblack_lines \u0026lt;- linesdf %\u0026gt;% filter(class == \"st14\") %\u0026gt;% mutate(horizontal = abs(y2 - y1) \u0026lt; 10 * abs(x2 - x1)) %\u0026gt;% mutate(vertical = !horizontal) ggplot(black_lines, aes(x = x1, xend = x2, y = y1, yend = y2, color = horizontal)) + geom_segment()   We can also look at the distribution of line lengths to be able to separate out the short \u0026lsquo;ticks\u0026rsquo;.\nggplot(black_lines, aes(x = length)) + geom_histogram() #\u0026gt; `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.   It looks like any line with length less than 30 will be a tick.\nticks \u0026lt;- black_lines %\u0026gt;% mutate(is_tick = length \u0026lt; 30) %\u0026gt;% filter(is_tick) horiz_limits \u0026lt;- ticks %\u0026gt;% filter(horizontal) %\u0026gt;% filter(y1 == max(y1) | y1 == min(y1)) vert_limits \u0026lt;- ticks %\u0026gt;% filter(vertical) %\u0026gt;% filter(x1 == max(x1) | x1 == min(x1)) #ggplot(bind_rows(horiz_limits, vert_limits), aes(x = x1, xend = x2, y = y1, yend = y2, color = horizontal)) + # geom_segment()   Now we can extract the positions of the maximum and minimum tick for each axis, and manually write in the real values those correspond to from the label:\nx_min_svg \u0026lt;- min(vert_limits$x1) x_max_svg \u0026lt;- max(vert_limits$x1) y_min_svg \u0026lt;- min(horiz_limits$y1) y_max_svg \u0026lt;- max(horiz_limits$y1)   We\u0026rsquo;ll also manually enter the corresponding real values from the tick labels\nx_min_real \u0026lt;- ymd(\"2020-04-26\") x_max_real \u0026lt;- ymd(\"2020-10-11\") y_min_real \u0026lt;- 10 y_max_real \u0026lt;- 40   We\u0026rsquo;ve dealt with the axes. Now time to move onto the points. Unfortunately they are not points, they are paths (bezier-curves), drawing circles to represent points!\nHere is a tool I found useful for interpreting SVG commands.\nWe\u0026rsquo;ll extract all the paths.\npaths \u0026lt;- xml_nodes(doc, \"path\")   And then try to split up the bezier curves into sub commands, like M (move to a point), C draw a curve in absolute coordinates, c draw a curve in relative coordinates, and so on.\npathsdf \u0026lt;- tibble(bind_rows(lapply(xml_attrs(paths), as.data.frame.list))) %\u0026gt;% mutate(id = 1:n()) %\u0026gt;% mutate(d = gsub(\"S\", \"|S\", d)) %\u0026gt;% mutate(d = gsub(\"s\", \"|s\", d)) %\u0026gt;% mutate(d = gsub(\"z\", \"|z\", d)) %\u0026gt;% mutate(d = gsub(\"c\", \"|c:\", d)) %\u0026gt;% mutate(d = gsub(\"C\", \"|C:\", d)) %\u0026gt;% mutate(d = gsub(\"M\", \"M:\", d)) %\u0026gt;% mutate(d = gsub(\"\\n\", \"\", d)) %\u0026gt;% mutate(d = gsub(\" \", \"\", d)) %\u0026gt;% mutate(d = gsub(\"([0-9])-\", \"\\\\1,-\", d)) commandsdf \u0026lt;- pathsdf %\u0026gt;% separate_rows(d, sep = \"\\\\|\") %\u0026gt;% filter(d != \"z\") %\u0026gt;% separate(d, into = c(\"command\", \"parameters\"), \":\") #\u0026gt; Warning: Expected 2 pieces. Missing pieces filled with `NA` in 24 rows [23, 25, 28, 30, 7933, 7935, 7938, 7940, 8673, 8675, 8678, 8680, 16233, 16235, 16238, 16240, 16243, 16245, 16248, 16250, ...]. commands_processed \u0026lt;- commandsdf %\u0026gt;% separate(parameters, into = c(\"p1\", \"p2\", \"p3\", \"p4\", \"p5\", \"p6\"), sep = \",\") %\u0026gt;% mutate(abs_x = case_when(command == \"M\" ~ p1, command == \"C\" ~ p5), abs_y = case_when(command == \"M\" ~ p2, command == \"C\" ~ p6)) %\u0026gt;% mutate(rel_x = case_when(command == \"c\" ~ p5), rel_y = case_when(command == \"c\" ~ p6)) #\u0026gt; Warning: Expected 6 pieces. Missing pieces filled with `NA` in 3796 rows [1, 6, 11, 16, 21, 26, 31, 36, 41, 46, 51, 56, 61, 66, 71, 76, 81, 86, 91, 96, ...].   These circles in SVG form curves, with 4 control points. If we take the average of these we can find the position of the point. One of the points is absolute, from the M coordinates, but 3 are from c commands, and they only have relative coordinates, so we need to calculate the cumulative sums of these, and then add them to the M coordinates. Then we\u0026rsquo;ll average out, and add back the class metadata.\nlowercase_cs \u0026lt;- commands_processed %\u0026gt;% group_by(id) %\u0026gt;% filter(command == \"c\") %\u0026gt;% mutate(rel_x_sum = cumsum(rel_x), rel_y_sum = cumsum(rel_y)) %\u0026gt;% select(id, rel_x_sum, rel_y_sum) zeroes \u0026lt;- lowercase_cs %\u0026gt;% group_by(id) %\u0026gt;% summarise(rel_x_sum = 0, rel_y_sum = 0) #\u0026gt; `summarise()` ungrouping output (override with `.groups` argument) full_relative_set \u0026lt;- bind_rows(lowercase_cs, zeroes) uppercase_cs \u0026lt;- commands_processed %\u0026gt;% filter(command == \"C\") %\u0026gt;% select(id, command, abs_x, abs_y) %\u0026gt;% mutate(abs_x = as.numeric(abs_x), abs_y = as.numeric(abs_y)) both \u0026lt;- inner_join(uppercase_cs, full_relative_set, by = \"id\") %\u0026gt;% mutate(x = abs_x + rel_x_sum, y = abs_y + rel_y_sum) point_types \u0026lt;- pathsdf %\u0026gt;% select(id, class) points \u0026lt;- both %\u0026gt;% group_by(id) %\u0026gt;% summarise(x = mean(x), y = mean(y)) %\u0026gt;% inner_join(point_types, by = \"id\") %\u0026gt;% mutate(y = -y) %\u0026gt;% filter(class %in% c(\"st10\", \"st7\", \"st9\", \"st12\", \"st11\", \"st5\")) #\u0026gt; `summarise()` ungrouping output (override with `.groups` argument)   Above you can see I have filtered to only some of the classes. This is because some points were represented by two curves, one a stroke and one a fill. Now let\u0026rsquo;s plot the points.\nggplot(black_lines, aes(x = x1, xend = x2, y = y1, yend = y2)) + geom_segment() + geom_point(data = points %\u0026gt;% mutate(x2 = 0, y2 = 0), aes(x = x, y = y, color = class)) + scale_color_brewer(type = \"qual\", palette = \"Paired\")   Conveniently, the points in the key are still there, so we can easily label these classes with their correct metadata\ngenes_detected \u0026lt;- c(1, 1, 2, 2, 3, 3) symptoms \u0026lt;- c(\"yes\", \"no\", \"yes\", \"no\", \"yes\", \"no\") classes \u0026lt;- c(\"st9\", \"st12\", \"st7\", \"st11\", \"st5\", \"st10\") class_info \u0026lt;- tibble(class = classes, symptoms = symptoms, genes_detected = genes_detected) points_detail \u0026lt;- points %\u0026gt;% inner_join(class_info) %\u0026gt;% mutate(genes_detected = as.factor(genes_detected)) #\u0026gt; Joining, by = \"class\" ggplot(black_lines, aes(x = x1, xend = x2, y = y1, yend = y2)) + geom_segment() + geom_point(data = points_detail %\u0026gt;% mutate(x2 = 0, y2 = 0), aes(x = x, y = y, color = genes_detected, shape = symptoms)) + scale_color_manual(values = c(\"red\", \"blue\", \"black\"))+scale_shape_manual(values=c(1,16))   We\u0026rsquo;re getting there! We have recreated the chart within our ggplot.\nNow we just need to transform ourselves into the right axes:\ntransform \u0026lt;- function(vector, a_in, a_out, b_in, b_out) \u0026#123; scaling \u0026lt;- (b_out - a_out) / (b_in - a_in) vector \u0026lt;- (vector - a_in) * scaling + a_out return(vector) \u0026#125; ytransform \u0026lt;- partial(transform, a_in = y_min_svg, a_out = y_min_real, b_in = y_max_svg, b_out = y_max_real) xtransform \u0026lt;- partial(transform, a_in = x_min_svg, a_out = x_min_real, b_in = x_max_svg, b_out = x_max_real) new_axes \u0026lt;- black_lines %\u0026gt;% mutate(y1 = ytransform(y1), y2 = ytransform(y2), x1 = xtransform(x1), x2 = xtransform(x2)) points_transformed \u0026lt;- points_detail %\u0026gt;% mutate(y = ytransform(y), x = xtransform(x)) ggplot(new_axes, ) + geom_segment(aes(x = x1, xend = x2, y = y1, yend = y2)) + geom_point(data = points_transformed %\u0026gt;% mutate(x2 = ymd(\"2020-01-01\"), y2 = ymd(\"2020-01-01\")), aes(x = x, y = y, color = genes_detected, shape = symptoms)) + scale_color_manual(values = c(\"red\", \"blue\", \"black\"))+scale_shape_manual(values=c(1,16))   OK, the coordinates look right. At this point we can throw away the old axes and just focus on the points.\nvalues \u0026lt;- points_transformed %\u0026gt;% filter(y \u0026gt; 0) %\u0026gt;% mutate(Date = x, Ct = y) %\u0026gt;% select(-x, -y, -class,-id) write_csv(values, \"ons_ct_value_genes_detected_and_symptoms.csv\") values #\u0026gt; # A tibble: 1,886 x 4 #\u0026gt; symptoms genes_detected Date Ct #\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;date\u0026gt; \u0026lt;dbl\u0026gt; #\u0026gt; 1 yes 3 2020-04-28 26.8 #\u0026gt; 2 yes 3 2020-04-28 21.7 #\u0026gt; 3 yes 3 2020-05-07 22.9 #\u0026gt; 4 yes 3 2020-05-09 29.4 #\u0026gt; 5 yes 3 2020-05-10 21.8 #\u0026gt; 6 yes 3 2020-05-10 27.3 #\u0026gt; 7 yes 3 2020-05-11 18.1 #\u0026gt; 8 yes 3 2020-05-11 16.8 #\u0026gt; 9 yes 3 2020-05-11 27.3 #\u0026gt; 10 yes 3 2020-05-13 19.3 #\u0026gt; # â¦ with 1,876 more rowsm   There\u0026rsquo;s our dataset.\nAnd here\u0026rsquo;s our graph.\nggplot(values,aes(x=Date,y=Ct,color=genes_detected,shape=symptoms)) + scale_color_manual(values = c(\"red\", \"blue\", \"black\"))+scale_shape_manual(values=c(1,16)) +geom_point()+theme_bw()+ theme(legend.position=\"bottom\")   as compared to: Now we can see what this data can tell us about Ct value distributions:\nWhat is the distribution of 1, 2, and 3 gene positives at different Ct values?\nggplot(values,aes(x=Ct,fill=genes_detected,y=..count..)) + scale_fill_manual(values = c(\"red\", \"blue\", \"black\")) + geom_density(alpha=0.3)   What is the distribution of Ct values with and without symptoms?\nggplot(values,aes(x=Ct,fill=symptoms,y=..count..)) + geom_density(alpha=0.3)   Does symptomatic Ct distribution vary over time?\nggplot(values,aes(x=Date,y=Ct,color=symptoms)) + geom_smooth() #\u0026gt; `geom_smooth()` using method = 'gam' and formula 'y ~ s(x, bs = \"cs\")'   (yes, it does \u0026ndash; which I hadn\u0026rsquo;t especially expected \u0026ndash; this may be because it includes symptoms either side of the test at any length of time, so at times of high Ct perhaps people aren\u0026rsquo;t mostly symptomatic at the time of testing)\nCrucially from the point of view of assessing B.1.1.7 proportions, we can calculate how we expect the number of genes detected to change with Ct value for wild-type SARS-CoV2.\nggplot(values,aes(x=Ct,fill=genes_detected,y=..count..)) + scale_fill_manual(values = c(\"red\", \"blue\", \"black\")) + geom_density(alpha=0.5,position=\"stack\")   This dataset gives us a sense of how much \u0026lsquo;false positive B.1.1.7\u0026rsquo; we might see from random S dropout at a range of different Ct values (i.e.Â the 2 values might be predominantly this).\nAnd we can even simulate what B.1.1.7 would look like under these conditions. We know that it is very rare to see the S positive unless OR and N are both also positive. So essentially B.1.1.7 SGTF would just turn 3 into 2 here.\nsimul_b117 = values %\u0026gt;% mutate(genes_detected=ifelse(genes_detected==\"3\",\"2\",genes_detected)) %\u0026gt;% filter(genes_detected\u0026gt;0) ggplot(simul_b117,aes(x=Ct,fill=genes_detected,y=..count..)) + scale_fill_manual(values = c(\"red\", \"blue\", \"black\")) + geom_density(alpha=0.5,position=\"stack\")   We can see that at high Ct, we see a lot of the single gene OR or N.\nWith the median Ct value around 31 in recent weeks, this can help to explain the presence of single gene positive samples that were previously called as not-compatible with the new variant.\n Conclusion We\u0026rsquo;ve been able to convert a valuable dataset generated by the ONS Infection Survey team into a machine-readable form, which permits insights into the apparent relative decline of B.1.1.7 in the recent report. Hopefully this can provide a useful building block in downstream analyses of Ct, gene dropout, and temporal dynamics.\n If you enjoyed this exploration of how to extract data from vector-graphics in R, you might also want to see my extraction of data from a rasterised chloropleth map.\n","date":1612347517,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1612347517,"objectID":"dd1d07ef5a7344894873416671a7e662","permalink":"/post/2021-02-02-ons_extraction/","publishdate":"2021-02-03T10:18:37Z","relpermalink":"/post/2021-02-02-ons_extraction/","section":"post","summary":"Summary: The ONS Coronavirus Infection Survey is an immensely valuable scientific project measuring prevalence of coronavirus in the community. However some useful data have been released only in graphical form which makes them hard to re-analyse.","tags":[],"title":"Turning a graph back into data","type":"post"},{"authors":[],"categories":[],"content":"Update(2021-02-03): Maccabi have also now released a different report looking at a cohort, which gives a less rosy picture of initial efficacy. The explanation may be the older age group in the cohort. I think the calculations below still stand, but am flagging this important further data for context.\n Maccabi have now released a preprint on Pfizer vaccine efficacy after the first dose. Let\u0026rsquo;s take a look at it.\nFirstly a little complaint. If you go to the `Data' tab on bioRxiv, it says:\nNow of course one understands that there may be lots of underlying patient data that can\u0026rsquo;t be released for regulatory reasons. But some data definitely can, because they release it in this preprint, in graphical form.\nAt bare minimum, we should demand that the data directly plotted in graphs are released in numerical form to permit further analysis. There can be no regulatory justification for not doing so.\nFortunately, the data are there, we just need to extract them. For this image file I did that by hand with WebPlotDigitizer.\nmaccabi = read_csv(\"maccabi.csv\",col_names = c('Day','CumulativeIncidence')) %\u0026gt;% mutate(Day=round(Day)) ggplot(maccabi,aes(x=Day,y=CumulativeIncidence))+geom_line(color=\"blue\")+theme_bw()+labs(x=\"Day\",y=\"Cumulative Incidence\")+scale_y_continuous(labels=scales::percent,limits=c(0,NA))   Looks like we\u0026rsquo;ve pretty much got it. Now let\u0026rsquo;s convert that cumulative incidence into a daily incidence (something not done in the Maccabi preprint).\nperday = maccabi %\u0026gt;% arrange(Day,CumulativeIncidence) %\u0026gt;% group_by(Day) %\u0026gt;% summarise(CumulativeIncidence=max(CumulativeIncidence)) %\u0026gt;% mutate(DailyIncidence=CumulativeIncidence-lag(CumulativeIncidence),type=\"Vaccinated\") ggplot(perday,aes(x=Day,y=DailyIncidence))+geom_line(color=\"blue\")+theme_bw()+labs(x=\"Day\",y=\"Daily Incidence\")+scale_y_continuous(labels=scales::percent,limits=c(0,NA))   Now we have a fair idea of what went on. On day 1 after vaccination, 0.024% of those vaccinated tested positive. That proportion seems to have risen until about day 8, when 0.06% of those vaccinated tested positive. It then fell until day 25, when just 0.005% tested positive.\nNow, to properly calculate vaccine efficacy we would need some control group who have not been vaccinated. In the original trials that was a randomly selected half who were given a placebo injection. We compared how many cases they developed, as compared to those who were vaccinated.\nThere is no placebo group here. No set of matching people who were not vaccinated. So to have any way of calculating an efficacy value we essentially have to invent one and imagine what the incidence would have been in it.\nDoing this for the first ~10 days, seems pretty easy. We really don\u0026rsquo;t expect to see the vaccine have any effect here, so the control group might look something like this:\ncontrol_group = tibble(Day=1:10,DailyIncidence=seq(0.00032,0.00059,length.out=10),type=\"Synthetic control\") ggplot(bind_rows(control_group, perday),aes(x=Day,y=DailyIncidence,color=type))+geom_line()+theme_bw()+labs(color=\"\",x=\"Day\",y=\"Daily Incidence\")+scale_y_continuous(labels=scales::percent,limits=c(0,NA)) +scale_color_manual(values=c(\"red\",\"blue\"))   The reason for this not being a horizontal line would have to be some genuine rise in cases over this period. One possibility is the general increasing number of cases in Israel, which continued up to around 15 Jan.Â Unforunately, having this synthetic control line for the first 7 days isn\u0026rsquo;t especially useful. By construction this shows ~0% efficacy in that period, because that\u0026rsquo;s what we designed it to. What I\u0026rsquo;m really interested is that the efficacy around Day 24. So how should we extend the line?\nI\u0026rsquo;ve illustrated 3 possible scenarios below, one where cases continue to rise in the placebo group, another where they stay flat, and another where they fall :\nsyn_control \u0026lt;- function(final, name,offset)\u0026#123; return(bind_rows(tibble(Day=1:10,DailyIncidence=seq(0.00032+offset,0.00059+offset,length.out=10),type=name), tibble(Day=10:25,DailyIncidence=seq(0.00059+offset,final,length.out=16),type=name)) ) \u0026#125; combo =bind_rows(syn_control(0.0010,\"Synthetic control: Growth\",0.00001),syn_control(0.00059,\"Synthetic control: flat\",0),syn_control(0.00029,\"Synthetic control: decreasing\",-0.00001), perday) ggplot(combo,aes(x=Day,y=DailyIncidence,color=type))+geom_line()+theme_bw()+labs(color=\"\",x=\"Day\",y=\"Daily Incidence\")+scale_y_continuous(labels=scales::percent,limits=c(0,NA)) +scale_color_manual(values=c(\"pink\",\"red\",\"darkred\",\"blue\"))   These choices have a substantial effect on the efficacy we measure for days 23-25, which range from 82% (placebo cases fall) to 94% (placebo cases rise).\ncombo %\u0026gt;% filter(Day\u0026gt;22) %\u0026gt;% group_by(type) %\u0026gt;% summarise(Incidence = mean(DailyIncidence)) %\u0026gt;% mutate(efficacy_percent = 100*(1- min(Incidence)/Incidence)) %\u0026gt;% filter(type!=\"Vaccinated\") %\u0026gt;% select(-Incidence) #\u0026gt; `summarise()` ungrouping output (override with `.groups` argument) #\u0026gt; # A tibble: 3 x 2 #\u0026gt; type efficacy_percent #\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; #\u0026gt; 1 Synthetic control: decreasing 82.4 #\u0026gt; 2 Synthetic control: flat 90.8 #\u0026gt; 3 Synthetic control: Growth 94.4   So what did Maccabi do? Well something quite different to any of these. They used the period from days 0 to 12 as the control for days 13 to 24. That looks like this:\ncontrol_group = perday %\u0026gt;% mutate(Day=Day+12, type= \"Synthetic control\") %\u0026gt;% filter(Day\u0026lt;25) maccabi_analysis = bind_rows(control_group, perday %\u0026gt;% filter(Day\u0026lt;25)) ggplot(maccabi_analysis,aes(x=Day,y=DailyIncidence,color=type))+geom_line()+theme_bw()+labs(color=\"\",x=\"Day\",y=\"Daily Incidence\")+scale_y_continuous(labels=scales::percent,limits=c(0,NA)) +scale_color_manual(values=c(\"red\",\"blue\"))   If again you look at day 23-24 efficacy here, you get an efficacy of 88%.\nmaccabi_analysis %\u0026gt;% filter(Day\u0026gt;22) %\u0026gt;% group_by(type) %\u0026gt;% summarise(Incidence = mean(DailyIncidence)) %\u0026gt;% mutate(efficacy_percent = 100*(1- min(Incidence)/Incidence)) %\u0026gt;% filter(type!=\"Vaccinated\") %\u0026gt;% select(-Incidence) #\u0026gt; `summarise()` ungrouping output (override with `.groups` argument) #\u0026gt; # A tibble: 1 x 2 #\u0026gt; type efficacy_percent #\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; #\u0026gt; 1 Synthetic control 87.5   Maccabi however looked across the entire period. If you do that you get an efficacy close to 50% (they got 51%, I got 56%, possibly due to slight differences in the weighting of different days based on the number of people in them).\nmaccabi_analysis %\u0026gt;% filter(Day\u0026gt;12) %\u0026gt;% group_by(type) %\u0026gt;% summarise(Incidence = mean(DailyIncidence)) %\u0026gt;% mutate(efficacy_percent = 100*(1- min(Incidence)/Incidence)) %\u0026gt;% filter(type!=\"Vaccinated\") %\u0026gt;% select(-Incidence) #\u0026gt; `summarise()` ungrouping output (override with `.groups` argument) #\u0026gt; # A tibble: 1 x 2 #\u0026gt; type efficacy_percent #\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; #\u0026gt; 1 Synthetic control 56.1   So, what to conclude? Essentially the way Maccabi analysed this data was one relatively arbitrary possibility among many. Efficacy estimates are quite sensitive to the guesses one makes about how many cases there would have been in the control group. Maccabi\u0026rsquo;s decision here is quite conservative in that it includes as a control group the day 10 to 12 period where some cases may well have been averted by vaccination.\nThe decision to look at the entire day 12-24 period rather than the end of it, will yield a result lower than the true efficacy towards the end of this period, given the clear evidence for an increase in efficacy over the period. This is incredibly valuable data, and all in all, things look pretty good.\nggplot(perday,aes(x=Day,y=DailyIncidence))+geom_line(color=\"black\")+theme_bw()+labs(x=\"Day\",y=\"Daily Incidence\")+scale_y_continuous(labels=scales::percent,limits=c(0,NA)) +geom_smooth() #\u0026gt; `geom_smooth()` using method = 'loess' and formula 'y ~ x'   perday #\u0026gt; # A tibble: 26 x 4 #\u0026gt; Day CumulativeIncidence DailyIncidence type  #\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;chr\u0026gt;  #\u0026gt; 1 0 0.0000251 NA Vaccinated #\u0026gt; 2 1 0.000269 0.000244 Vaccinated #\u0026gt; 3 2 0.000626 0.000357 Vaccinated #\u0026gt; 4 3 0.000990 0.000363 Vaccinated #\u0026gt; 5 4 0.00149 0.000501 Vaccinated #\u0026gt; 6 5 0.00197 0.000476 Vaccinated #\u0026gt; 7 6 0.00247 0.000501 Vaccinated #\u0026gt; 8 7 0.00303 0.000564 Vaccinated #\u0026gt; 9 8 0.00365 0.000614 Vaccinated #\u0026gt; 10 9 0.00413 0.000489 Vaccinated #\u0026gt; # â¦ with 16 more rowsm incidence_data = read_csv(\"data_from_chart.csv\") #\u0026gt; Parsed with column specification: #\u0026gt; cols( #\u0026gt; Day = col_double(), #\u0026gt; VaccinatedCohort = col_double() #\u0026gt; ) cohort_size=132015 incidence_data$CumulativeIncidence = cumsum(incidence_data$VaccinatedCohort)/ cohort_size incidence_data$type = \"Incidence plot\" maccabi_offset = maccabi %\u0026gt;% filter(Day\u0026gt;3) %\u0026gt;% mutate(CumulativeIncidence = CumulativeIncidence-min(CumulativeIncidence), type=\"Kaplan-Meier plot\" ) ggplot(bind_rows(incidence_data,maccabi_offset),aes(color=type, group=type, x=Day,y=CumulativeIncidence))+geom_line()+theme_bw()+labs(x=\"Day\",y=\"Cumulative Incidence\")+scale_y_continuous(labels=scales::percent,limits=c(0,NA)) +scale_color_manual(values=c(\"darkgreen\",\"red\"))  ggsave(\"comparison.png\",type=\"cairo\",width=7,height=3)   ","date":1612088317,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1612088317,"objectID":"43668f211ae3b5fccf38541fb8594be8","permalink":"/post/2021-01-31-maccabi-2/","publishdate":"2021-01-31T10:18:37Z","relpermalink":"/post/2021-01-31-maccabi-2/","section":"post","summary":"Update(2021-02-03): Maccabi have also now released a different report looking at a cohort, which gives a less rosy picture of initial efficacy. The explanation may be the older age group in the cohort.","tags":[],"title":"Looking again at Maccabi data for efficacy after initial Pfizer dose","type":"post"},{"authors":[],"categories":[],"content":"This exciting chart has emerged from the Maccabi study, providing evidence for efficacy of the Pfizer vaccine after the first dose.\nAs Eran Segal pointed out on Twitter, the blue line actually includes the green line. I was interested to see what this would look like replotted as a Kaplan-Meier curve like the Pfizer graph.\nsize_of_cohort = 50777 size_of_all_members = 480000 size_of_unvaccinated = size_of_all_members-size_of_cohort data = data %\u0026gt;% mutate(new_infections_all_members = AllMembersNormalised*size_of_all_members/size_of_cohort) data = data %\u0026gt;% mutate(new_infections_unvaccinated = new_infections_all_members - VaccinatedCohort) data = data %\u0026gt;% mutate(daily_incidence_unvaccinated = new_infections_unvaccinated/size_of_unvaccinated) data = data %\u0026gt;% mutate(daily_incidence_vaccinated = VaccinatedCohort/size_of_cohort) graphdata = data %\u0026gt;% select(c(Day,contains(\"daily_incidence\"))) %\u0026gt;% pivot_longer(-Day,names_to=\"group\",values_to=\"daily_incidence\") %\u0026gt;% separate(group,into=c(\"bla\",\"bla2\",\"condition\"),sep=\"_\") %\u0026gt;% select(-contains(\"bla\")) %\u0026gt;% group_by(condition) %\u0026gt;% arrange(Day) %\u0026gt;% mutate(cumulative_incidence=cumsum(daily_incidence)) graphdata$condition = ifelse(graphdata$condition==\"unvaccinated\",\"Control cohort\",graphdata$condition) ggplot(graphdata,aes(x=Day,y=cumulative_incidence,color=condition))+geom_line()+theme_classic()+labs(caption=\"Caveats: based on 7-day-moving average data so sharpness of start of initial efficacy will be understated. \\n Control cohort may contain vaccinated people\",color=\"Condition\",y=\"Cumulative Incidence\")+scale_color_manual(values=c(\"red\",\"blue\"))+geom_point()   There are a lot of caveats about whether this is comparing like-for-like in terms of endpoint. In some respects it is definitely not, and everything is smoothed out by the 7 day moving average. In addition, this is a much older age group where we\u0026rsquo;d very much expect the immune response to take longer. Another really important caveat is that the blue line likely includes people who were vaccinated later on.\nIn general the top plot presented by Maccabi is much more useful for getting a sense of what is going on (what direction the lines are pointing at the end of the Kaplain-Meier plot).\n","date":1611353917,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1611353917,"objectID":"a0767b949c46f9b244f4ed605d57a27a","permalink":"/post/2021-01-022-maccabi/","publishdate":"2021-01-22T22:18:37Z","relpermalink":"/post/2021-01-022-maccabi/","section":"post","summary":"This exciting chart has emerged from the Maccabi study, providing evidence for efficacy of the Pfizer vaccine after the first dose.\nAs Eran Segal pointed out on Twitter, the blue line actually includes the green line.","tags":[],"title":"Analysing Maccabi data on initial efficacy of first vaccine dose","type":"post"},{"authors":[],"categories":[],"content":"Code behind this analysis: https://github.com/theosanderson/theo.io/tree/master/content/post/2021-01-22-ons-data\nThe ONS infection survey has come out and there has been a lot of discussion on the apparent decrease in proportion of \u0026ldquo;new variant compatible\u0026rdquo; cases.\nTo try to understand these patterns we need to go into a bit more detail. How are \u0026ldquo;new variant compatible\u0026rdquo; cases defined?\nThe TaqPath tests that produce this data amplify parts of three genes in the SARS-CoV2 genome:\n The N gene ORF1ab The S gene  We know that B.1.1.7 often gives complete loss of the S-gene amplicon (data from Portugal suggest it doesn\u0026rsquo;t always).\nWhen B.1.1.7 was emerging the ONS defined a fairly conservative definition of \u0026ldquo;new variant compatible\u0026rdquo; tests. They said that these must be positive for N, and ORF1AB, but not for S. That is what we would expect to see for B.1.1.7 when there a lot of virions in the sample. But if a sample has a low number of virions, one or other of these genes might randomly drop below the detection threshold. Fortunately the ONS also report the data split out by each of the possible amplicon combinations, so we can examine this.\nFirst let\u0026rsquo;s convince ourselves that, irrespective of B.1.1.7, dropouts of amplicons can occur for various reasons. Let\u0026rsquo;s look at the distribution of amplicons period of time in September, before B.1.1.7 had really emerged.\nsubset = data %\u0026gt;% filter(week==\"2020-09-21\") %\u0026gt;% filter(RegionType==\"EnglandRegion\") %\u0026gt;% mutate(AmpliconType = case_when( Amplicons %in% c(\"N only\",\"N+S\",\"OR only\",\"OR+S\",\"S only\") ~ \"Random dropout\", Amplicons == \"OR+N+S\" ~ \"Definite non-B.1.1.7\", Amplicons == \"OR+N\" ~ \"Likely(?) B.1.1.7\" )) ggplot(subset,aes(x=AmpliconType,y=Count,fill=Amplicons))+geom_bar(stat=\"identity\")+facet_wrap(~Region)+theme_bw()+ theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))   I\u0026rsquo;ve separated out the OR+N amplicon types, which the ONS considers new variant compatible. Let\u0026rsquo;s ignore these for now. We can see that there is a substantial variation in the other amplicon groups. If there were no random dropout (and no other variants that compromise an assay), we would expect everything else to be OR+N+S. But in the South West these make up a minority of the total positives identified. Instead it seems that some of these amplicons are randomly dropping out there.\nWe can also see a lot of geographical heterogeneity in the level of this random dropout. What drives this? We also have the mean Ct values for each region so we can test the hypothesis that high Ct values (low number of virions), due to a higher proportion of infections being identified longer after the original infection, are responsible for the \u0026ldquo;random dropout\u0026rdquo;.\n# Exclude suspected B.1.1.7 from the data subset = data %\u0026gt;% filter(week==\"2020-09-21\") %\u0026gt;% filter(RegionType==\"EnglandRegion\") %\u0026gt;% filter(Amplicons!=\"OR+S\") #Calculate the proportion with \"no random dropout\", then invert to get proportion of \"random dropout\" subset =subset %\u0026gt;% group_by(Region) %\u0026gt;% mutate(proportion = Count/sum(Count)) %\u0026gt;% filter(Amplicons==\"OR+N+S\") %\u0026gt;% mutate(RandomDropout=1-proportion) subset_cts = data_ct %\u0026gt;% filter(week==\"2020-09-21\") %\u0026gt;% filter(RegionType==\"EnglandRegion\") both \u0026lt;- inner_join(subset,subset_cts) #\u0026gt; Joining, by = c(\"Region\", \"RegionType\", \"week\") ggplot(both,aes(x=Mean,y=RandomDropout,label=Region))+geom_point()+labs(x=\"Mean Ct value\",y=\"Proportion of 'random dropout'\")+geom_text_repel()+theme_bw()+scale_y_continuous(labels=scales::percent)+labs(\"Relationship between Ct and levels of random dropout in September\")   Having convinced ourselves that random dropouts can occur at different levels due to differences in Ct values (and that Ct values can differ due to epidemiological dynamics)), we can examine whether an increased rate of random dropouts in the N or ORF1ab genes (or both!) might cause an underestimation of B.1.1.7 prevalence when considering only OR+N+S as compatible with the new variant.\nNow lets look at the trajectories of all amplicon groups over time in England.\ndata = data %\u0026gt;% group_by(Region,week) %\u0026gt;% mutate(proportion = Count/sum(Count)) ggplot(data%\u0026gt;% filter(Region==\"England\"), aes(x=week,y=proportion,color=Amplicons))+geom_line()+theme_bw()+scale_y_continuous(labels=scales::percent)  data$Amplicons = factor(as.character(data$Amplicons),levels = c(\"S only\",\"OR+S\",\"N+S\",\"OR+N+S\",\"N only\",\"OR only\",\"OR+N\")) p\u0026lt;-ggplot(data%\u0026gt;% filter(Region==\"England\")%\u0026gt;% filter(Amplicons!=\"S only\"), aes(x=week,y=proportion,fill=Amplicons))+geom_area()+theme_bw()+scale_y_continuous(expand=c(0,0),labels=scales::percent)+scale_fill_brewer(type=\"qual\",palette=4)+labs(x=\"Date\",y=\"Proportion\")+scale_x_date(expand=c(0,0)) ggsave(\"plot.pdf\",width=5,height=3)   An annotated version of that plot: ggplot(data%\u0026gt;% filter(RegionType==\"EnglandRegion\")%\u0026gt;% filter(Amplicons!=\"S only\"), aes(x=week,y=proportion,fill=Amplicons))+geom_area()+theme_bw()+scale_y_continuous(expand=c(0,0),labels=scales::percent)+scale_fill_brewer(type=\"qual\",palette=4)+labs(x=\"Date\",y=\"Proportion\")+scale_x_date(expand=c(0,0)) +facet_wrap(~Region)  ggsave(\"plotregion.png\",width=7*1.2,height=4*1.2)   We can see a rise in OR+N over time. But this seems to tail off to at least horizontal at the end. Does this mean that B.1.1.7 is no longer increasing at the expense of other variants? Well I don\u0026rsquo;t think we have evidence for this. OR+N may be horizontal, but OR+N+S seems likely to be decreasing faster. It is likely that this is due to a general change in the epidemic stage, as lockdown controls new infections and a higher proportion of old detections are detected.\nAgain if we want to look for an explanation we can investigate the Cts.\nggplot(data_ct%\u0026gt;% filter(RegionType==\"EnglandRegion\"),aes(x=week, y=Mean))+geom_line() +labs(title=\"Regions\")+facet_wrap(~Region)+theme_bw()+labs(y=\"Mean Ct value\")   In all regions we see an increase in mean Ct over January, which we\u0026rsquo;d expect to cause more random dropouts, and reduce the number of both WT viruses that appear as OR+N+S and of B.1.1.7 viruses that appear as OR+N.\nOne (imperfect) way to try to get a handle on this is to just plot the ratio of OR+N+S to OR+N, because both of these are affected by random drop out.\nggplot(data%\u0026gt;% filter(Region==\"England\",Amplicons %in% c(\"OR+N+S\",\"OR+N\")),aes(x=week, fill=Amplicons,y=Count))+geom_bar(stat=\"identity\",position=\"fill\")+scale_y_continuous(labels=scales::percent) +labs(title=\"England\")  ggplot(data%\u0026gt;% filter(RegionType==\"EnglandRegion\",Amplicons %in% c(\"OR+N+S\",\"OR+N\")),aes(x=week, fill=Amplicons,y=Count))+geom_bar(stat=\"identity\",position=\"fill\")+scale_y_continuous(labels=scales::percent) +labs(title=\"Regions\")+facet_wrap(~Region)   Similarly we can also plot how the proportion of B.1.1.7 incompatible cases (those that do show S amplification) has changed.\ndata = data %\u0026gt;% mutate(B117_incompatible = grepl('S',Amplicons)) ggplot(data%\u0026gt;% filter(Region==\"England\",Amplicons %in% c(\"OR+N+S\",\"OR+N\")),aes(x=week, fill=B117_incompatible,y=Count))+geom_bar(stat=\"identity\",position=\"fill\")+scale_y_continuous(labels=scales::percent) +labs(title=\"England\")  ggplot(data%\u0026gt;% filter(RegionType==\"EnglandRegion\",Amplicons %in% c(\"OR+N+S\",\"OR+N\")),aes(x=week, fill=B117_incompatible,y=Count))+geom_bar(stat=\"identity\",position=\"fill\")+scale_y_continuous(labels=scales::percent) +labs(title=\"Regions\")+facet_wrap(~Region)   to be continued\n","date":1611325117,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1611327517,"objectID":"3800c68c5bc9f94ca4db84360770cd23","permalink":"/post/2021-01-22-ons-data/","publishdate":"2021-01-22T14:18:37Z","relpermalink":"/post/2021-01-22-ons-data/","section":"post","summary":"Code behind this analysis: https://github.com/theosanderson/theo.io/tree/master/content/post/2021-01-22-ons-data\nThe ONS infection survey has come out and there has been a lot of discussion on the apparent decrease in proportion of \u0026ldquo;new variant compatible\u0026rdquo; cases.","tags":[],"title":"New-variant compatibility in the ONS infection survey","type":"post"},{"authors":[],"categories":[],"content":"The latest round of the REACT study has come out, and been quite controversial. Let\u0026rsquo;s examine some of the raw data behind it.\nlibrary(tidyverse)   Let\u0026rsquo;s download the REACT data and process it into a nice format:\npositive \u0026lt;- read_csv(url(\"https://raw.githubusercontent.com/mrc-ide/reactidd/master/inst/extdata/positive.csv\")) #\u0026gt; Warning: Missing column names filled in: 'X1' [1] total \u0026lt;- read_csv(url(\"https://raw.githubusercontent.com/mrc-ide/reactidd/master/inst/extdata/total.csv\")) #\u0026gt; Warning: Missing column names filled in: 'X1' [1]   positive$type = \"positive\" total$type = \"total\" all = bind_rows(positive, total) colnames(all)[1] = \"Date\" all = all %\u0026gt;% pivot_longer(c(-Date,-type),names_to=\"Region\") %\u0026gt;% pivot_wider(names_from=type) all #\u0026gt; # A tibble: 1,485 x 4 #\u0026gt; Date Region positive total #\u0026gt; \u0026lt;date\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; #\u0026gt; 1 2020-05-05 South East 0 113 #\u0026gt; 2 2020-05-05 North East 0 13 #\u0026gt; 3 2020-05-05 North West 1 73 #\u0026gt; 4 2020-05-05 Yorkshire and The Humber 0 33 #\u0026gt; 5 2020-05-05 East Midlands 1 77 #\u0026gt; 6 2020-05-05 West Midlands 0 51 #\u0026gt; 7 2020-05-05 East of England 0 93 #\u0026gt; 8 2020-05-05 London 0 39 #\u0026gt; 9 2020-05-05 South West 0 42 #\u0026gt; 10 2020-05-06 South East 0 62 #\u0026gt; # â¦ with 1,475 more rowsm   Now we can calculate binomial confidence intervals by location for each date and plot them.\nall = all %\u0026gt;% filter(!is.na(positive)) %\u0026gt;% filter(!is.na(total)) library(binom) cis = binom.confint(all$positive,all$total, method=\"exact\") all$lower=cis$lower all$mean = cis$mean all$upper=cis$upper ggplot(all %\u0026gt;% filter(Date\u0026gt;\"2020-12-15\"),aes(x=Date,ymin=lower,ymax=upper,y=mean))+geom_pointrange(color=\"black\") +facet_wrap(~Region,scales=\"free_y\")+scale_y_log10(labels = scales::percent)+theme_bw() + labs(y=\"Probability of testing positive\") #\u0026gt; Warning: Transformation introduced infinite values in continuous y-axis #\u0026gt; Warning: Transformation introduced infinite values in continuous y-axis  ggsave(\"plot.png\",width=9,height=5, type=\"cairo\") #\u0026gt; Warning: Transformation introduced infinite values in continuous y-axis #\u0026gt; Warning: Transformation introduced infinite values in continuous y-axis   This looks to accord well with the table of R values that REACT provide in Table 3: This isn\u0026rsquo;t especially surprising, but I think the visualisation helps to make sense of how these values came to be calculated (even though they are probably based on a more complex analysis weighting for various demographic factors).\nThat\u0026rsquo;s it for now.\n","date":1611251917,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1611248317,"objectID":"370d26cc6b5d239c6c4032dfbd22c46a","permalink":"/post/2021-01-21-react/","publishdate":"2021-01-21T17:58:37Z","relpermalink":"/post/2021-01-21-react/","section":"post","summary":"The latest round of the REACT study has come out, and been quite controversial. Let\u0026rsquo;s examine some of the raw data behind it.\nlibrary(tidyverse)   Let\u0026rsquo;s download the REACT data and process it into a nice format:","tags":["COVID","R notebook"],"title":"Investigating the latest round of REACT","type":"post"},{"authors":[],"categories":[],"content":"One framing for thinking about COVID is as a race between vaccination and infection, since we expect the former to have at least some mitigating effect on the latter. To get a sense for this I plot the cumulative infection estimates from the MRC Biostatistics Nowcasting Reports against the vaccination numbers from PHE (with historical data filled in from Our World in Data).\ntry(library(tidyverse), silent=TRUE) library(jsonlite) library(ggthemes) a = fromJSON(\"mrc_biostats.json\") df=tibble(date=a[[1]],y=a[[2]]) df$date=lubridate::ymd(df$date) df$label = \"People infected\" b = read_csv(\"vaccinations.csv\") b$y=b$numFirstDose b$date=lubridate::dmy(b$date) b$label = \"People vaccinated\" ggplot(bind_rows(df,b),aes(x=date,y=y/1000000,color=label))+geom_line(size=1) +labs(x=\"Date\",y=\"Number of people (millions)\",color=\"Type\",title=\"Infection and vaccination levels in England\",caption=\"Data sources: MRC Biostatistics Unit (cumulative infection estimates)\\nOur World In Data \u0026amp; PHE (vaccination figures â at least one dose)\")+theme_hc()++ theme(plot.title = element_text(hjust = 0.5))  ggsave(\"plot.png\",width=7.3,height=4, type = \"cairo\")   If we literally were to imagine vaccination and infection to be mutually exclusive (which clearly isn\u0026rsquo;t true in either direction), we could plot a graph like this to look at where they might meet.\nc=b c$label = \"People unvaccinated\" c$y=56000000-c$y ggplot(bind_rows(df,c),aes(x=date,y=y/1000000,color=label))+geom_line(size=1) +labs(x=\"Date\",y=\"Number of people (millions)\",color=\"Type\",title=\"Infection and vaccination levels in England\",caption=\"Data sources: MRC Biostatistics Unit (cumulative infection estimates)\\nOur World In Data \u0026amp; PHE (vaccination figures â at least one dose)\")+theme_hc()++ theme(plot.title = element_text(hjust = 0.5))  ggsave(\"plot2.png\",width=7.3,height=4, type = \"cairo\")   ","date":1611248317,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1611248317,"objectID":"b202c229e6cbcfbbbceaaa0e86afbec0","permalink":"/post/2021-01-21-vaccine-virus/","publishdate":"2021-01-21T16:58:37Z","relpermalink":"/post/2021-01-21-vaccine-virus/","section":"post","summary":"One framing for thinking about COVID is as a race between vaccination and infection, since we expect the former to have at least some mitigating effect on the latter. To get a sense for this I plot the cumulative infection estimates from the MRC Biostatistics Nowcasting Reports against the vaccination numbers from PHE (with historical data filled in from Our World in Data).","tags":[],"title":"The virus vs. the vaccine","type":"post"},{"authors":["Francois Korbmacher","Benjamin Drepper","Theo Sanderson","Peer Martin","Thomas Stach","Alexander G Maier","Kai Matuschewski","Joachim M Matz"],"categories":null,"content":"","date":1609459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1609459200,"objectID":"f348b254187f7a0ee829453d396e3a5b","permalink":"/publication/korbmacher-2021-apicoplast/","publishdate":"2021-01-21T16:48:35.970428Z","relpermalink":"/publication/korbmacher-2021-apicoplast/","section":"publication","summary":"","tags":null,"title":"An apicoplast-resident folate transporter is essential for sporogony of malaria parasites","type":"publication"},{"authors":["Eerik Aunin","Ulrike BÃ¶hme","Theo Sanderson","Noah D. Simons","Tony L. Goldberg","Nelson Ting","Colin A. Chapman","Chris I. Newbold","Matthew Berriman","Adam J. Reid"],"categories":null,"content":"","date":1596240000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1596240000,"objectID":"0913c5c2f829de01bfaf26c4c0d43729","permalink":"/publication/2020-hepatocystis/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/2020-hepatocystis/","section":"publication","summary":"This work began when I did a BLAST search for a malaria parasite gene, and saw a closely matching gene that claimed to be from a monkey. When I investigated further I found that this \"monkey genome\" contained substantial contamination from a genus of parasite called *Hepatocystis* that had been lurking in the monkey's blood. The identification of the first substantial genomic data from this genus, which I initially described in a [blog post](/blog/2018/04/23/how-i-stumbled-upon-a-novel-genome-for-a-malaria-like-parasite-of-apes/), triggered a collaborative project between the originators of the data, former colleagues at the Sanger Institute, and myself to characterise this genome revealing the genomic basis of this parasite's unique biology.","tags":[],"title":"Genomic and transcriptomic evidence for descent from Plasmodium and loss of blood schizogony in Hepatocystis parasites from naturally infected red colobus monkeys","type":"publication"},{"authors":null,"categories":["COVID"],"content":"I recently asked on Twitter:\nAnd got reassuring results:\nThen I asked another question. Have a think about how you might answer it.\nHere is how Twitter responded:\nQuite a difference! Not surprising perhaps. The risk of passing on COVID-19 is lower by a factor of 12,000. Nevertheless, I think that the good people of Twitter are wrong, and will explain why a little further down.\nThe people of Twitter are not alone though, and these sorts of decisions arenât just thought experiments. The UK government first required people with coughs or fever to isolate themselves on 12 March, long after the virus arrived in the UK. This was part of the governmentâs strategy of introducing âthe right measures at the right timeâ, and Sir Patrick Vallance gave this as an example, saying that prior to 12 March a very small proportion of people with symptoms would have COVID-19, so it would not make sense to isolate them.\nIâve seen a similar argument made against mask use. After lockdown a small proportion of people will have COVID, the argument goes, so the chance of any particular mask stopping an infection is tiny:\nWe do this sort of risk analysis all the time. When you go somewhere in a car there is some small chance you could cause an accident in which someone is hurt, but if that risk were 12,000 times higher you would never drive again.\nEven some experts appear to agree:From The Times, 21st April\nBut this argument does not apply for a contagious virus.\nInvestigating with a simple model Practically, someone who stays home in Scenario A (when there is a 99.999% chance they have a cold), has the same impact as someone who stays home when there is a 12% chance they have COVID. One way to see this is to simulate an epidemic, and imagine that we institute an intervention for only a week, either early in the epidemic or late in the epidemic.\nLetâs consider the mass-masking scenario. Without any interventions, each infected person passes the virus on to 2.5 additional people. Weâll exaggerate the effect of masks and imagine that everyone wearing masks reduces that number (R) to 0.8. In reality this magnitude of effect could only be achieved with a package of many interventions. But it makes it easier to see whatâs going on with a graph.\nIf we plot the epidemic with a logarithmic y-axis, then the steepness of the line is a reflection of how many people each infected person passes the virus to. So if we donât implement any interventions, this graph goes up with a constant slope.\nWhat happens if we wait until lots of people have the virus, and then bring in masks for 2 weeks to try to stop them passing it on? Well, itâs as youâd expect. The graph goes up as normal, then goes down as R falls to 0.8 for 2 weeks, then starts going up at the same rate again, but reaches a lower point after 80 days than without the two week intervention.\nIn this case we decided to bring in the 2 week intervention only after at least 1% of people were infected. This seems to make sense. Surely there is no point in making people wear masks when only 0.001% of them have the virus? But letâs check, what happens if we bring in the two weeks much earlier in the epidemic?\nIt turns out that the two weeks early in the epidemic has exactly the same effect on the number of infections on day 80! What matters is that it has the same effect on R in either case. Even though a far lower absolute number of infected people are wearing masks, R is reduced to 0.8 in both cases.\nEthics: how should we each act in the time of COVID-19? As COVID-19 was spreading in our communities, many people advocated for social-distancing measures. One model for doing this is to think about the absolute chance you have of spreading the virus. For example, someone made a graph to discourage people from holding large events by showing that if there are a lot of infections in the community there is a good chance that large events will cause transmission events:\nInterestingly this graph suggests that if one holds a large event when there is a low level of COVID in the community, there is a less negative effect than when there is a high level. But weâve seen from the models above that this isnât correct.\nSo how can we decide how to shape our behaviour? I think it makes sense to follow Kantâs âCategorical Imperativeâ.\n Act only according to that\u0026nbsp;maxim\u0026nbsp;whereby you can, at the same time, will that it should become a universal law.  So imagine if everyone acted as you intend to, and work out what the effect on R would be. If everyone wears masks then, regardless of the level of COVID in the community, R is reduced. If everyone holds large events then, regardless of the level of COVID in the community, R is increased.\nIn the absence of evidence on seroprevalence and immunity, we must aim to keep R below 1 until we have a vaccine. This will drive the level in the community down to near zero. It will allow vulnerable people to go about their lives as normal. However to achieve these levels we must sustain our measures even as levels in the community drop. Even as we believe that only 30 people in the whole country are infected, we must all wear masks. Itâs counter-intuitive, but it will work.\n","date":1587475601,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1587475601,"objectID":"eada8f5d9e3bc30488ddf5921ca7bab3","permalink":"/blog/2020/04/21/covid-19-and-the-categorical-imperative/","publishdate":"2020-04-21T13:26:41Z","relpermalink":"/blog/2020/04/21/covid-19-and-the-categorical-imperative/","section":"post","summary":"I recently asked on Twitter:\nAnd got reassuring results:\nThen I asked another question. Have a think about how you might answer it.\nHere is how Twitter responded:\nQuite a difference!","tags":null,"title":"COVID-19 and the categorical imperative","type":"post"},{"authors":null,"categories":["COVID"],"content":"Until recently, the strategy for COVID testing in many countries has been focused on people who have a significantly likelihood of having COVID-19. The need to impose unpleasant social distancing measures, and ultimately complete lock-downs, trades off against how much testing you do in the community. With sufficient community testing, you could suppress COVID in a population without any social distancing measures. This post is an outline of one way one might go about testing 25 million people per week in order to achieve this.\nDecentralised testing Reaching this sort of scale quickly is likely to require a decentralised approach levering existing organisations. The most obvious candidates to do this are schools and larger businesses. Thirteen million people are employed by businesses with more than 50 employees, and there are twelve million children in schools. If these businesses and schools could test everyone within them each week, 25 million tests would be carried out.\nItâs important to note that this sort of testing is completely different from the testing of symptomatic, or likely infected, individuals. Symptomatic testing rightly requires specialist training, uncomfortable nasopharyngeal swabs, and full PPE for the person testing and the person being tested. This is because there is a high risk of exposure to COVID-19, and because getting a test result wrong could have major implications for care.\nTesting random individuals from a population with low incidence of COVID-19 poses no greater risk than interacting with them in any other way, as colleagues or students. And in this setting a significant rate of false-negatives or false-positives can be tolerated without major consequences.\nTesting procedure In this proposal all of these businesses and schools would be supplied with: simple nasal swabs, frozen plates containing COVID-19 RT-PCR mix, a basic one-button thermocycler, a blue light transilluminator.\nThe employee responsible for testing takes one of the frozen plates out of the freezer and thaws it.\nStudents and employees go up, one by one, to the testing station. Each person takes a nasal swab and swabs their nostril (front-of-nose, not nasopharyx), then places the swab into a well of the plate, and cuts off the swabâs shaft and discards it. They also write their name on a sheet in a box representing this well, then wash their hands.\nOnce the plate is full of samples the employee responsible for testing takes the plate. They seal it, load it into the one-button-thermocycler, and press the button. The thermocycler runs an RT-PCR programme for an hour.\nThe employee takes the plate out of the machine and examines it with the blue light transilluminator. Any positive wells (including a pre-loaded control well) will glow brightly. Negative wells will be dull.\nIf the employee notices any positive wells (a very rare occurence) they immediately look at the sheet of names and contact the person in question to ask them to report to public health authorities for confirmatory testing. If this test comes back positive then contact-tracing begins.\nThe aim would be to test each person at these schools and businesses once each week.\nCosts and availability The reagents for this test cost much less that Â£1 per tested person.\nA thermocycler is a simple device which can be currently be purchased for Â£3,200, and likely manufactured for much less. Unlike ventilators, these could be relatively easily produced by other manufacturers. There would be a definite need to scale up production to achieve this scale.\nA blue light transilluminator can be made for less than Â£40 from commonly available materials.\nIt seems likely that, despite their low-cost, global supplies of RT-PCR enzymes are insufficient for this scale of testing at present. But there is no reason I am aware of to think that this could not easily be scaled up. The quantities of primers needed are readily available.\nThere might be a need to scale up the production of the DNA-binding dye.\nAll of these costs are minuscule compared to the economic losses averted by preventing a lock-down.\n","date":1587302926,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1587302926,"objectID":"87601f325e40c18062c76d4709b5fa33","permalink":"/blog/2020/04/19/community-testing-for-covid-19-reaching-25-million-tests-per-week/","publishdate":"2020-04-19T13:28:46Z","relpermalink":"/blog/2020/04/19/community-testing-for-covid-19-reaching-25-million-tests-per-week/","section":"post","summary":"Until recently, the strategy for COVID testing in many countries has been focused on people who have a significantly likelihood of having COVID-19. The need to impose unpleasant social distancing measures, and ultimately complete lock-downs, trades off against how much testing you do in the community.","tags":null,"title":"Community testing for COVID-19: reaching 25  million tests per week","type":"post"},{"authors":null,"categories":["COVID"],"content":"Update: it seems (although clarity is lacking) that the UK has moved away from the herd-immunity strategy. I very much welcome this. It renders the argument below irrelevant, except as an illustration of the weaknesses of a strategy that seeks to vaccinate a population using an epidemic.\nDisclaimer: I am neither a virologist, nor an immunologist, nor an epidemiologist. This post is written with confidence, because too many caveats hinder clarity, but should be understood to be the thoughts of a layperson. This week the policy of the UK government on COVID-19, under advice from scientists, has been articulated clearly for the first time. The government intends for around 60% of the population to be infected with COVID-19 in the anticipation that after the majority who survive recover, the population as a whole will have âherd immunityâ to the virus, since if only 40% of the population can pass on the virus it will be unable to spread.\nOne can argue about the wisdom of the policy, which is in disagreement with the position of the WHO and many other countries. This post is not about that. What I am interested in is: given this policy (to allow 60% of the population to become infected), what is the least bad way to achieve this? For instance, should you let the virus spread at random through the population or should you actively infect people with the virus under very controlled conditions to minimise the risks?\nThe current approach\nThe governmentâs approach is to allow the virus to spread with relatively few restrictions initially. At a point before it overwhelms the healthcare system, it will introduce further social-distancing measures to attempt to âflatten the curveâ and spread the 40 million infections over a longer time. There will also be some measures to try to ensure that the most vulnerable â older and immunocompromised people â are isolated, but it is unclear how effectively this can be achieved.\nRisks of the current approach\n**Infecting the vulnerable. ~**20% of the UK population is over 65. The fatality rate appears at least 10x higher in this demographic group, hence the governmentâs attempts to isolate them. At a point where a substantial portion of the population has the virus it is likely to be very difficult to achieve this. If the 60% of the 3.2 million people over 80 became infected, and the fatality rate of 14% for this age-group from China applied then that would represent 270,000 deaths in this age group alone.\nOverloading the healthcare system. Exponential growth is a powerful adversary and small miscalculations could result in overloading the healthcare system with the result that many people die simply because there are no ventilators available to keep them alive. There is concern among some experts that it will not be possible to flatten the curve enough to ensure thatÂ everyone receives adequate care. Exponential growth is difficult to avoid in natural infections because people who get the virus will not initially know that they have it, and so will unknowingly spread it to others.\nViral load. There are reasons to expect that the more particlesÂ of virus a person is exposed to initially, the more likely they areÂ to experience severe disease. In the governmentâs approach there is no control over this and so it is possible that young and healthy people may develop severe symptoms due to exposure to a large viral load.\nAn alternative approach\nWe have seen that the government actively intends for 60% of people to get the virus. It is almost as if it were to simply go and infect people, as at a chicken-pox party.Â So why not actually do this? Could there be advantages to actively exposing 60% of people in a controlled way to the virus to generate the same herd immunity?\nAdvantages the controlled exposure approach\nNot infecting the vulnerableÂ  â only fit and healthy people would be selected to receive the virus. Almost no children under 10 have developed severe symptoms from COVID-19. It would therefore seem very safe to put all immunocompetent children into the 60% who get the virus. Other young people are also comparatively resilient to the virus, and so a utilitarian argument would suggest they wouldÂ be the safest people to inoculate with the virus. We will see below that this approach may be safer for the peopleÂ who get infected, than the alternative policy of letting the virus pass through the population.\nNot overloading the healthcare systemÂ  â there are two ways in which this controlled approach would avoid overloading the healthcare system. Firstly, by avoiding exponential growth: those infected would know they had been infected and could be isolated afterwards until they were no longer shedding virus. Once resistant, they could go out into the population, and safely work in crucial roles where they were likely to be exposed to the virus. Secondly by reducing the hospitalisation rate: because these people would be drawn from a much more resilient population the chances of them developing severe symptoms would be much lower. The end result of this would be fewer people in hospitals, meaning that the small(er) number of people who did develop severe symptoms would be able to get adequate care. The end result might be that a 100% chance of being infected, and receiving adequate care if required, might be safer than a 60% chance of being infected with the possibility of developing severe symptoms in a degraded healthcare system, which is dealing with exponential growth and vulnerable patients.\nControlled viral load, and possibility of an attenuated strain â there are several lines of evidence to suggest that the amount of virus one is initially exposed to may be a determinant of whether someone develops severe symptoms. By controlling the infection one could minimise the amount of virus someone is exposed to (while ensuring they develop an immune response). ThisÂ might again substantially reduce the risk compared to a 60% chance of receiving a random viral load (determined by how near you are to an infected person and how much virus they are shedding). Finally, although proper âno-riskâ vaccines are unlikely to be available for some time, my non-expert brain wonders whether it is possible to rapidly develop a version of the virus that would be expected to be mildly attenuated by, for example, leaving the proteins the virus is encoding exactly the same, but altering the âcodonsâ of DNA such that these proteins are likely to be produced less rapidly. The effectiveness of this could not be guaranteed, but on the balance of probabilities it seems very unlikely to be more dangerous than the wild-type virus.\nSummary\nThe government are conducting an experiment in whichÂ they will allow 60% of people to be infected. To my mind this is in substance the same as the government randomly choosing 60% of people and actively infecting them with a random load of wild-type virus, but not telling them they are infected with the result that they may spread it to vulnerable people. An alternative approach in which selected resilient people were infected in a controlled manner with a low-dose of an attenuated virus might be safer for the people infected, as well as society at large, than the current strategy.\nDisclaimer\nI am neither a virologist, nor an immunologist, nor an epidemiologist. I would welcome explanations of where this argument falls down from such people, or anyone else. Furthermore, I am not arguing for this approach as superior to a containment strategy, merely as superior to a strategy of natural infection. Finally, this is a suggestion for an organised governmental approach, not a DIY âchicken-pox party approachâ which would not control viral load and would therefore have great risk.\n","date":1584191068,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1584191068,"objectID":"0f98dfc40d72258c7f3068f08f353ada","permalink":"/blog/2020/03/14/controlled-infection-with-covid-19-as-a-safer-means-of-establishing-herd-immunity/","publishdate":"2020-03-14T13:04:28Z","relpermalink":"/blog/2020/03/14/controlled-infection-with-covid-19-as-a-safer-means-of-establishing-herd-immunity/","section":"post","summary":"Update: it seems (although clarity is lacking) that the UK has moved away from the herd-immunity strategy. I very much welcome this. It renders the argument below irrelevant, except as an illustration of the weaknesses of a strategy that seeks to vaccinate a population using an epidemic.","tags":null,"title":"Controlled infection with COVID-19 as a safer means of establishing herd immunity","type":"post"},{"authors":["Brandon Carter","Maxwell Bileschi","Jamie Smith","Theo Sanderson","Drew Bryant","David Belanger","Lucy J Colwell"],"categories":null,"content":"","date":1577836800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1577836800,"objectID":"d00b02156ce50508d9d3d14a09a6ada4","permalink":"/publication/carter-2020-critiquing/","publishdate":"2021-01-21T16:48:35.959458Z","relpermalink":"/publication/carter-2020-critiquing/","section":"publication","summary":"","tags":null,"title":"Critiquing protein family classification models using sufficient input subsets","type":"publication"},{"authors":["Manuela Carrasquilla","Sophie Adjalley","Theo Sanderson","Alejandro Marin-Menendez","Rachael Coyle","Ruddy Montandon","Julian C Rayner","Alena Pance","Marcus CS Lee"],"categories":null,"content":"","date":1577836800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1577836800,"objectID":"78ceaeb1ba293a9f041abcd2175cfa19","permalink":"/publication/carrasquilla-2020-defining/","publishdate":"2021-01-21T16:48:35.967436Z","relpermalink":"/publication/carrasquilla-2020-defining/","section":"publication","summary":"","tags":null,"title":"Defining multiplicity of vector uptake in transfected Plasmodium parasites","type":"publication"},{"authors":["Catherine F Houlihan","Nina Vora","Thomas Byrne","Dan Lewer","Gavin Kelly","Judith Heaney","Sonia Gandhi","Moira J Spyer","Rupert Beale","Peter Cherepanov"," others"],"categories":null,"content":"","date":1577836800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1577836800,"objectID":"e4e3d1f872be450643690d156d6fc0b4","permalink":"/publication/houlihan-2020-pandemic/","publishdate":"2021-01-21T16:48:35.968434Z","relpermalink":"/publication/houlihan-2020-pandemic/","section":"publication","summary":"","tags":null,"title":"Pandemic peak SARS-CoV-2 infection and seroconversion rates in London frontline health-care workers","type":"publication"},{"authors":["Crick Covid Consortium"],"categories":null,"content":"","date":1577836800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1577836800,"objectID":"f95aa9c114091058a6c797ca6d68990d","permalink":"/publication/consortium-2020-scalable/","publishdate":"2021-01-21T16:48:35.969431Z","relpermalink":"/publication/consortium-2020-scalable/","section":"publication","summary":"","tags":null,"title":"Scalable and Robust SARS-CoV-2 Testing in an Academic Center","type":"publication"},{"authors":["Michael D Buck","Enzo Z Poirier","Ana Cardoso","Bruno Frederico","Johnathan Canton","Sam Barrell","Rupert Beale","Richard Byrne","Simon Caidan","Margaret Crawford"," others"],"categories":null,"content":"","date":1577836800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1577836800,"objectID":"c76dce6e008e206b4255046f80c3ba9a","permalink":"/publication/buck-2020-standard/","publishdate":"2021-01-21T16:48:35.972423Z","relpermalink":"/publication/buck-2020-standard/","section":"publication","summary":"","tags":null,"title":"Standard operating procedures for SARS-CoV-2 detection by a clinical diagnostic RT-LAMP assay","type":"publication"},{"authors":["Duncan N Ndegwa","Jessica B Hostetler","Alejandro Marin-Menendez","Theo Sanderson","Kioko Mwikali","Lisa H Verzier","Rachael Coyle","Sophie Adjalley","Julian C Rayner"],"categories":null,"content":"","date":1577836800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1577836800,"objectID":"628c277077de769adbcc26eae328cad8","permalink":"/publication/ndegwa-2020-using/","publishdate":"2021-01-21T16:48:35.969431Z","relpermalink":"/publication/ndegwa-2020-using/","section":"publication","summary":"","tags":null,"title":"Using Plasmodium knowlesi as a model for screening Plasmodium vivax blood-stage malaria vaccine targets reveals new candidates","type":"publication"},{"authors":[],"categories":[],"content":"Create slides in Markdown with Wowchemy Wowchemy | Documentation\n Features  Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides   Controls  Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export: E   Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026quot;blueberry\u0026quot; if porridge == \u0026quot;blueberry\u0026quot;: print(\u0026quot;Eating...\u0026quot;)   Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = ;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\n Fragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}}  Press Space to play!\nOne  Two  Three \n A fragment can accept two optional parameters:\n class: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears   Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}}  Press the S key to view the speaker notes!\n Only the speaker can read these notes Press S key to view    Themes  black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links    night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links   Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026quot;/media/boards.jpg\u0026quot; \u0026gt;}} {{\u0026lt; slide background-color=\u0026quot;#0000FF\u0026quot; \u0026gt;}} {{\u0026lt; slide class=\u0026quot;my-style\u0026quot; \u0026gt;}}   Custom CSS Example Let\u0026rsquo;s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; }   Questions? Ask\nDocumentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549324800,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"/slides/example/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/example/","section":"slides","summary":"An introduction to using Wowchemy's Slides feature.","tags":[],"title":"Slides","type":"slides"},{"authors":null,"categories":["Mini-projects"],"content":"There are a lot of tweets to PubMed pages â not least from @MalariaPapers. I made PubTweetÂ to enable these to have nice info-boxes, like this:\nEvaluation of automated malaria diagnosis using the Sysmex XN-30 analyser in a clinical setting. https://t.co/ZA0vb59FzQ  \u0026mdash; Malaria Papers (@MalariaPapers) January 24, 2019  ","date":1548387802,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1548387802,"objectID":"8f4eb741cca780acb9a371b49b312632","permalink":"/blog/2019/01/25/pubtweet/","publishdate":"2019-01-25T03:43:22Z","relpermalink":"/blog/2019/01/25/pubtweet/","section":"post","summary":"There are a lot of tweets to PubMed pages â not least from @MalariaPapers. I made PubTweetÂ to enable these to have nice info-boxes, like this:\nEvaluation of automated malaria diagnosis using the Sysmex XN-30 analyser in a clinical setting.","tags":null,"title":"PubTweet","type":"post"},{"authors":null,"categories":["Automation"],"content":"In my PhD lab we had an epMotion 5075 pipetting robot. I had a like/hate relationship with this machine. Like: itâs an impressive, precision-engineered, piece of hardware. Hate: the software is appalling. Writing protocols for it was slow, frustrating and generally awful, and there was a general lack of flexibility in what one could make it do.\nRecently I heard that the lab was having a clear out, including disposing of this (pricey when purchased) robot and I asked if I could adopt it in preference to the scrapheap, which I was kindly allowed to. Iâm not in a wet-lab at the moment so for now it will live in a garage, but I did want to have a peek inside to have a better understanding of how it works, and to work out whether it would be possible to customise it to be more flexible.\nIf I were buying my own scientific hardware I would always go for the upstart companies like OpenTrons and IncuversÂ which tell you how their hardware works and allow you to do whatever you want with it. With the epMotion, by contrast, if you want to use new labware you have to send a physical version of it to the company which they measure to generate a proprietary calibration file.\nI was given some hope that it might be possible to customise the robot from this video, in which someone has replaced all the electronics of the robot with a standard board for a CNC machine:\n\nBut other than that I could find very little on the internet about what is inside these robots. I think thatâs a shame, and now I have one at my disposal, without a warranty. So here is a run-down of what happens when you take it apart, in case it is useful to anyone in a similar position.\nFirst steps\nThe back panels come off very easily with a hex-key and expose the computer that runs the machine. This runs some version of Windows, maybe Windows CE. It has USB and ethernet ports although to my knowledge with my version of this robot these canât be used for anything useful. In general I doubt there is any easy way to make this computer do anything other than what Eppendorf has programmed it to do, without access to the underlying source code.\nRemoving the top required in my case removing a little bit of double sided tape at either side, in addition to two hex-key bolts.\nThere is a heavy-duty belt for the X axis with a big stepper motor.Â My robot had been essentially unused for several years and the rail over which the X-carriage runs had become covered with a sticky substance. This caused the motors to stall mid-run, but cleaning them off with some alcohol resolved this issue.\nThe computer that is the brains of the operation \u0026#8211; unfortunately unlikely to be easily repurposable. Basics\nEach of the X, Y and Z axes is controlled by a stepper motor (the X-axis one is this). They each have optical endstops with 4 wires. In the video above these endstops have been replaced with mechanical switches but it really should be possible to use them as-is.\nX-belt and optical end-stop Y-axis stepper motor, belt, and optical end-stop. Cabling\nOne of the challenges of making a many-axis robot is that signals have to be carried to each successive axis, all of which are connected together. So flexible cabling is needed -but at the same time it has to not get in the way or fall into the samples. In the case of the epMotion this is carried out with ribbon cables like this:\nBut it quickly becomes apparent that this cable doesnât have enough wires to be simply directly connected at the other end to stepper motors / endstops / etc. Instead it seems that this is some sort of serial cable that carries data signals to a series of other microprocessors, one on the robotâs pipetting arm, and one for each of the Y and Z axes, which then interface with the Y motor, Z motor, the tool locking motor, the pipetting motor, the tip-ejecting actuator, and the range-detector.\nIf you want to hack this thing youâll have to decide whether you want to have to make and mount 4 separate pieces of control hardware, or to replace the cabling with a much thicker set of wires.\nPipetting arm\nLurking under the metal cover of the tool arm is a profusion of electronics. Thereâs a lot to do. An (infrared?) sensor to measure distance, and actuation of grabbing a tool, identifying it, pipetting up and down, and ejecting a tip.\nSelecting/using tools\nOne of the very impressive things about the epMotion robot is its ability to change tools during operation. It can choose from a variety of single channel and multichannel pipettes, and even a plate gripper.\nTools How does this process work?\nThe tool arm has two coaxial motors. One is, I believe, a simple DC motor with a very low gearing. It rotates a bit of metal internal to the arm which causes it to firmly grip whichever tool it is currently over. Iâm not quite sure how the robot knows when this rotation is finished. My suspicion is that it detects the change in current flowing through the motor when the motor stalls at the end. Certainly if you disconnect this motor, the robot is able to detect that âthe engine is not respondingâ, and informs you so.\nLooking up at the inside of the tool gripper to see how it works. When one examines the pipettes themselves one notices they have electrical contacts, but these are simply used to tell the robot which tool is in what place. The pipettes are in fact mechanical rather than electronic devices. They all have the same rotatable top-piece, and as this is spun by a stepper motor in the tool arm they aspirate/dispense liquid (or in the case of the gripper, grab and release). As this piece is rotated the tool begins to extend a rod out from it. Inside the tool-gripper this rod must make contact with a switch, and this is used to âhomeâ the pipette to ensure the robot knows the position of the plunger.\nHomed tool with thin rod extended to make contact with switch. Electrical contacts for tool ID visible to the right. Prospects for customisation\nIâm going to pause my hardware work here, because it isnât yet clear exactly what the application of the robot will be for me and I donât want to destroy any necessary functionality.\nIf I had continued I would have one way or another tried to marry up the epMotion hardware with the open-source OpenTrons robot-control software. This basically means adapting the hardware such that one knows how to control it and then writing a custom driver for the OpenTrons software.\nI do think this is completely achievable. The video above already shows how 3-axis control is possible, using a standard CNC board. Controlling aspirate/dispense as a fourth axis should be similarly simple. If my understanding of how the tool interlock works is correct than that also wouldnât be too challenging â one would just need to measure the current flowing through the motor. An even simpler strategy would just be to keep one tool locked onto the machine.\nOne decision one would have to make would be whether to have a single control board and have lots and lots of wires running to the tool-arm, or to use the existing ribbon cables and have a separate controller on the tool arm controlled over serial. I suspect the latter might be the better approach.\nMore generally, if I do this I will have to consider whether I want to be limited to expensive epMotion robot tips, the only ones compatible with any of these tools. I suspect the answer is no. In that case I might end up bolting an OT-2 electronic pipette to the pipetting arm, though this again loses the advantages of tool-changing. Or maybe Iâll go with something completely different like a vacuum pump and a peristaltic pump â weâll see.\nIn general none of this looks trivial, and one is almost certainly better off just buying an inexpensive OT2. Still, itâs nice to have a better understanding of what is going on inside this intricately engineered machine.\nÂ Update:\nIt has just occurred to me (another useful reason for writing things down) that there may be an easier and less invasive way to get control of this thing. If one can reverse engineer the serial control that the computer uses to control the Y-axis, Z-axis, tool interlock, aspiration tip ejection (and distance measuring) then one can get control of all of these without messing with their hardware. It seems possible that this could be achieved relatively simply (if they are sent in a text-based format) and when I have access to the machine again in 6 months time I will investigate. The 8 leads in the ribbon cable could be: V+, GND, Y-out, Y-in, Z-out, Z-in, pipette-out, pipette-in.\n","date":1546709915,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1546709915,"objectID":"2147ca9144b0d89af7a7202dc35e23cb","permalink":"/blog/2019/01/05/emotion-5075-teardown/","publishdate":"2019-01-05T17:38:35Z","relpermalink":"/blog/2019/01/05/emotion-5075-teardown/","section":"post","summary":"In my PhD lab we had an epMotion 5075 pipetting robot. I had a like/hate relationship with this machine. Like: itâs an impressive, precision-engineered, piece of hardware. Hate: the software is appalling.","tags":null,"title":"eMotion 5075 teardown","type":"post"},{"authors":["Rebecca R Stanway*","Ellen Bushell*","Anush Chiappino-Pepe*","Magali Roques*","Theo Sanderson","Blandine Franke-Fayard","Reto Caldelari","Murielle Golomingi","Mary Nyonda","Vikash Pandey"," others"],"categories":null,"content":"","date":1546300800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1546300800,"objectID":"a2f04b0e5e0a98c982c7261cc66b50ff","permalink":"/publication/stanway-2019-genome/","publishdate":"2021-01-21T16:48:35.961452Z","relpermalink":"/publication/stanway-2019-genome/","section":"publication","summary":"","tags":null,"title":"Genome-scale identification of essential metabolic processes for targeting the Plasmodium liver stage","type":"publication"},{"authors":["Charles Hillier","Mercedes Pardo","Lu Yu","Ellen Bushell","Theo Sanderson","Tom Metcalf","Colin Herd","Burcu Anar","Julian C Rayner","Oliver Billker"," others"],"categories":null,"content":"","date":1546300800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1546300800,"objectID":"1c413dcbe594151277f0dc9eb028654e","permalink":"/publication/hillier-2019-landscape/","publishdate":"2021-01-21T16:48:35.960455Z","relpermalink":"/publication/hillier-2019-landscape/","section":"publication","summary":"","tags":null,"title":"Landscape of the Plasmodium interactome reveals both conserved and species-specific functionality","type":"publication"},{"authors":["Lisa H Verzier","Rachael Coyle","Shivani Singh","Theo Sanderson*","Julian C Rayner*"],"categories":null,"content":"","date":1546300800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1546300800,"objectID":"97cedfbf79212a91ac6a33136b004a99","permalink":"/publication/verzier-2019-plasmodium/","publishdate":"2021-01-21T16:48:35.958461Z","relpermalink":"/publication/verzier-2019-plasmodium/","section":"publication","summary":"","tags":null,"title":"Plasmodium knowlesi as a model system for characterising Plasmodium vivax drug resistance candidate genes","type":"publication"},{"authors":["Manuela Carrasquilla","Theo Sanderson","Ruddy Montandon","Julian Rayner","Alena Pance","Marcus Lee"],"categories":null,"content":"","date":1546300800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1546300800,"objectID":"b77ca796d767219420805c3c4e100c3d","permalink":"/publication/carrasquilla-2019-quantitation/","publishdate":"2021-01-21T16:48:35.959458Z","relpermalink":"/publication/carrasquilla-2019-quantitation/","section":"publication","summary":"","tags":null,"title":"Quantitation of vector uptake reveals non-Poissonian transfection dynamics in Plasmodium falciparum","type":"publication"},{"authors":["Maxwell L Bileschi","David Belanger","Drew H Bryant","Theo Sanderson","Brandon Carter","D Sculley","Mark A DePristo","Lucy J Colwell"],"categories":null,"content":"","date":1546300800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1546300800,"objectID":"d49e257d035379996d725c5a621b9264","permalink":"/publication/bileschi-2019-using/","publishdate":"2021-01-21T16:48:35.957463Z","relpermalink":"/publication/bileschi-2019-using/","section":"publication","summary":"","tags":null,"title":"Using deep learning to annotate the protein universe","type":"publication"},{"authors":null,"categories":["ML","Non-bio"],"content":"The state of the art in image generation is BigGAN.\nNow, some trained models have been made available, including the capacity to interpolate between classes. I made a colab to easily create animations from these.\nThey are pretty fun.\nWhat is more, they make it clear that the latent space clearly captures very meaningful shared properties across classes. The poses of quite different animals are conserved, and âcat eyesâ clearly map onto âdog eyesâ during interpolation. These sort of properties suggest that the network âunderstandsâ the scene it is generating.\nHere are some more:\n(this one moves in latent space as well as class space, hence the change of pose:)\nChurches to mosques:\n       ","date":1542120717,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1542120717,"objectID":"998dadf51533566b5ff66d23841cdb58","permalink":"/blog/2018/11/13/biggan-interpolations/","publishdate":"2018-11-13T14:51:57Z","relpermalink":"/blog/2018/11/13/biggan-interpolations/","section":"post","summary":"The state of the art in image generation is BigGAN.\nNow, some trained models have been made available, including the capacity to interpolate between classes. I made a colab to easily create animations from these.\nThey are pretty fun.\nWhat is more, they make it clear that the latent space clearly captures very meaningful shared properties across classes. The poses of quite different animals are conserved, and âcat eyesâ clearly map onto âdog eyesâ during interpolation. These sort of properties suggest that the network âunderstandsâ the scene it is generating.\n","tags":null,"title":"BigGAN interpolations","type":"post"},{"authors":null,"categories":["ML"],"content":"In the last post I introduced neural networks, generative adversarial networks (GANs) and InfoGANs.\nIn this post Iâll describe the motivation and strategy for creating a GAN which generates images of biological cells, like this:\nMotivation\nTwo microscopic of cells from an identical cell-line are never going to be pixel-for-pixel identical, yet they still share key similarities in terms of morphology. One way to get a computer to demonstrate it âunderstandsâ these morphological properties is to force it to create images of new cells. When a model is capable of generating any image that might be taken of a specific cell one might argue that it has gained some knowledge about the cell.\nThis is an appealing approach as it is is easy to acquire large numbers of static images of cells, for instance by using an imaging flow cytometer. This device flows cells past a camera and acquires thousands of images each second, each with a large number of fluorescent channels. These are static images of course, but if they come from an synchronous population they should contain representatives of every stage in the cell cycle. If our generative model was sufficiently capable of truly understanding the structure in the data (and there is evidence that such models do) then provided if we could generate a model where one dimension in our generator corresponded to pseudotime we could generate timecourse âvideosâ from models trained on these single images. This would, apart from anything else, have practical utility, avoiding the problems of photobleaching in imaging.\nWhat I did\nFrom my work at the Rayner lab at the Sanger Institute I have access to a large dataset of images of infected red blood cells acquired with an imaging flow cytometer. These images contain both a brightfield transmitted light channel and a fluorescent channel showing DNA in the parasite. I used some filtering (with a classification network) to isolate only images containing single cells which were fully visible. I then trained an InfoGAN in much the same way as in the digit dataset described in the last post.\nI tried a couple of different versions, one with a large number of âcommunicatedâ values â which is what you see above.\nThe network learns about quite a few aspects of Plasmodium\nbiology, and also some basic optics:\n It learns about red blood cell morphology and to produce images of plausible cells It learns that the nucleus in the DAPI channel is always within the bounds of the RBC in the brightfield channel. It learns that there are a subset of cells (schizonts) which have both black haemozoin, and widespread, bright DAPI nuclei (often arranged in a circular shape) It learns that cells can appear in front of or behind the focal plane and how to render both types. I could go on.. the images produced by the network are almost all entirely plausible images that a biologist would be unable to distinguish from true parasites.  As an aside I really like watching this network cycle between samples, it is strikingly similar to watching a motile cell wriggling:\nI also trained a second version, with many fewer communicated variables, which really lets us see what the network sees as the most salient features. Unsurprisingly, these are mostly about the location and orientation of the red blood cell. Interestingly this network makes one of the parameters the focal position of the cell:\nFor any cell you look at, one end of this variable produces one type of halo, and the other the opposite, just as if this parameter was controlling the focus of a microscope.\nThis property illustrates the sort of property it would be really exciting to get the network to learn. In an ideal world the sliders would represent something like: focus, cell orientation and parasite lifecycle stage. So if you had a young ring stage parasite and you wanted to watch it mature you could just drag the slider across. Or if you wanted to focus on the far side of the cell you could just drag another slider. Such an idea may sound fanciful, but I donât think itâs too far away.\nThere are a number of simple ways I could improve the work Iâve done here. The network has to capture the complete distribution of cellular images presented as ârealâ. In this case you can see that these are in many different orientations, and different positions in the image. So a vast amount of the networks efoort goes into recapturing that, not very interesting, spatial variation. I made some basic attempts to align the images presented to the network, but this is something I could definitely improve. Something you will see as the cells dance from one space in the network to another is that while the nucleus tends to move smoothly around the black haemozoin will often fade out in one location and appear in another. The lack of smoothness here is an example of âmodal collapseâ that often haunts GANs, but there are a number of ways to tackle it.\nIn short, this work just scratches the surface of what what I suspect is possible with generative models of biological cells.\nIn some organisms there are genome-wide fluorescent-tag libraries available. Building a generative model using these (possibly with the need for some pairwise imaging) could allow the creation of a synthetic cell in which every protein can be simultaneously visualised. Itâs an exciting prospect, and I think itâs nearer than it seems.\nP.S. I belatedly looked for similar published work, and found two cool papers. The second of these introduces a star-shaped network designed to allow alignment in much the way I imagine at the end of this post. And more generally there are a ton of GAN papers applying the technique to super-resolution microscopy, in silico staining, etc.\n","date":1538474706,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1538474706,"objectID":"020048b9762db95f9a60b94c782d0b73","permalink":"/blog/2018/10/02/adventures-with-infogans-towards-generative-models-of-biological-images-part-2/","publishdate":"2018-10-02T10:05:06Z","relpermalink":"/blog/2018/10/02/adventures-with-infogans-towards-generative-models-of-biological-images-part-2/","section":"post","summary":"In the last post I introduced neural networks, generative adversarial networks (GANs) and InfoGANs.\nIn this post Iâll describe the motivation and strategy for creating a GAN which generates images of biological cells, like this:\n","tags":null,"title":"Adventures with InfoGANs: towards generative models of biological images (part 2)","type":"post"},{"authors":null,"categories":["ML"],"content":"I recently began an AI Residency at Google, which I am enjoying a great deal. I have been experimenting with deep-learning approaches for a few years now, but am excited to immerse myself in this world over the coming year. Biology increasingly generates very large datasets and I am convinced that novel machine-learning approaches will be essential to make the most of them.\nAt the beginning of my residency, I was advised to complete aÂ mini-project which largely reimplements existing work, as an introduction to new tools.Â In this post Iâm going to describe what I got up to during that first few weeks, which culminated in the tool below that conjures up new images of red blood cells infected with malaria parasites:\n function resizeIframe(obj) { obj.style.height = obj.contentWindow.document.body.scrollHeight + 'px'; } \n\nIâm going to try to explain it from first principles, which might take a while, so if you have a background in machine-learning, skip to the next post.\nNeural net-what?\nDeep learning is based around things called neural networks. A neural network takes a series of numbers in, does some processing to them, and ultimately spits out another set of numbers. A system like this is in theory capable of undertaking a great many tasks: for example the first series of numbers could be the brightness values for each pixel in an image, and the number outputted could be the probability that the image contains a cat. If the network can map those sets of numbers to each other successfully, then you have a cat-recognition network.\nA hypothetical classification network to detect images of cats But what determines whether the network will recognise cats,Â koalas, or fail to recognise anything at all? Each network contains a vast array of parameters, which determine how the input numbers are processed to produce the output. These are knobs which can be twiddled to make the network do different things.\nThe magic that makes neural networks powerful is a process calledÂ back-propagation, which allows the system to automatically twiddle these knobs until the network produces the desired output for each input. This requires a large amount of labelled data. For our cat network we might give it 1,000 photos of cats, and 1,000 photos of dogs. The system will start off by setting the parameters to random values. It will then feed in the first cat photo and see what number it gets out. With these random values, the network will most likely output 0.5 as the cat probability, even though the true value is 1 (itâs a cat!). But with back-propagation the system can observe this error (0.5 â 1 = -0.5) and calculate which direction it needs to turn each knob (and by how much) to make the error smaller. If we repeat this process over and over and over again (which is called training), we will eventually we find we have a network that can reliably distinguish cats and dogs. And it turns out that the graphics cards in our computers can be commandeered to make that process happen pretty quickly. In an hour or so we can have our cat recognition network â jubilations.\nWith those basic principles one can build a network to do any sort of classification problem. If you have searched your own photos based on what they containÂ (e.g. on Google photos) then you have interacted with just such a network.\nMaking computers creative\nYou might think at this point that our network has a pretty good idea what a cat looks like, but unfortunately with this approach you canât ask it to draw one.\nOne can imagine a neural network which could draw, however: this time theÂ output would be a series of numbers, which we will convert into to the brightness values of pixels in an image. What should the input be? It turns out we can just use random numbers:Â for each image we can sample say 10 values from a normal distribution, and feed them in. That way, in theory, the network can draw on this randomness to generate a different picture each time, and act as an image generator.\nThere is a problem of course. The network still has no idea what cats look like. When it is created, with its knobs set to random positions, it will generate images that resemble those on an un-tuned TV. In theory we could train it ourselves, by letting it know whenever it produced noise that had the faintest of resemblance to a cat, until it was coaxed into doing what we wanted. In practice however, this would take an eternity.\nSo what to do? Well, thereâs a trick, invented just four years ago, which has been revolutionary. We can introduce a second network, called a discriminator. This is a classification network, like the one we imagined above. But this time its task is not to distinguish cats from dogs, but to distinguish real photos of actual cats, from fake cats imagined by the generator. We feed it some real cats, and some fake âcatsâ that the generator has produced, and we train it. Initially it has a very easy job here, since remember the generator is just displaying the images of an untuned TV. But wait..\nOnce the discriminator starts to do a decent job we can take ourÂ back-propagation one step further. The system can backpropagate from the final result (âfakeâ or ârealâ) back to the pixel values produced by the generator, and then all the way back throughÂ the generatorÂ to the random variables that made these fake images. Then it can ask âwhat directions should I turn the knobs of the generator so that it produces an output that the discriminator thinks is real?â. In this way, the generator can be trained to fool the discriminator, and in doing so, the images it produces will become a bit more cat-like.\nThe discriminator can now be trained again, to be more expert in telling these synthetic cats from their real counterparts. In fact we bounce back and forth, training generator and then discriminator in a continual loop. They have opposing goals, the generator wants to make realistic cat images and the discriminator wants to tell these apart fromÂ true cat images, and so this architecture is called a generative adversarial network or GAN. After a long period of training these networks can produceÂ results like these:\nResults of a cat GAN. (This figure comes from a [paper][4] by Alexia Jolicoeur-Martinea about a novel type of discriminator) And with some extensions of the GAN approachÂ [Nvidia][5] were able to hallucinate these wholly imaginary celebrities. Not bad, eh?\nInfoGAN â images that communicate information\nThis approach can produce realistic images. But the relationship between the random noise at the beginning and the image at the end is not generally clear. If we increase value 3 by 50% what will happen? It is generally difficult to predict, and does not correspond in a useful way to a semantically meaningful property of the image.\nThere would be a lot of value to a network which, without being specifically trained to, could actually understand the structure in these images (e.g. that there are different breeds of cat) and that at the end could generate an image of any breed of your choice.\nSome people came up with a very clever way of doing this, called an InfoGAN. This approach is very similar to the original GAN. The generator still draws on random noise to produce its image. However the generator is also given someÂ extra noise, which it is tasked with encoding into the image it produces. For instance in the original InfoGAN paper the researchers produced a network which made images of hand-written digits. The extra noise they added was a discrete âone-hotâ variable with ten possible values. The idea was to create a network where each of these values corresponded to a different digit. To get this to happen they created an additional training objective for both the generator and the discriminator. As before, the discriminator still wants to distinguish real images from fake images andÂ the generator still wants to fool the discriminator. However both the discriminator and the generator are also rewarded if the discriminator is able to successfully reconstruct the extra random variable that was fed to the generator.\nThis means the generator now has to encodeÂ information (a variable with ten possible values) into an image, but that image has to be a plausible member of the set ofÂ hand-written digit images. The strategy that it ends up taking is to encode each value as a separate digit, and tada, we have achieved our goal. We can now ask the network to generate any specific digit we like. We can choose threes and generate an infinite number of different threes in different styles. The researchers also showed that if they added two more continuous variables to be communicated, these ended up mapped to the angle, and the width, of the digit produced.\nÂ Figure from the InfoGAN paper showing the three properties the network has learnt (digit type, angle and width) I began by reimplementing some of what these researchers had achieved, focusing on this hand-written digit task. Here are the images my network produced evolving over time:\nYou can see the network gradually deciding how it will encode each value. It is undecided about what should be a five and what should be a zero for a long time, but it eventually comes to a conclusion. So without labelling any of the data, the system has learnt to partition it into ten appropriate categories, and has built a system for arbitrarily generation members of each of these categories.\nThere are a near-infinite number of possible threes that can be drawn â cleaner or curlier, thicker or thinner, but all are united in being threes. I think that a very similar property applies in biological cells and in the next post Iâll describe my forays into this area, and the promise I think such an approach holds.\n\u0026raquo;\u0026raquo; Part 2\n","date":1538470846,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1538470846,"objectID":"bffc5ca71df553dcd9d074cf83e2cf95","permalink":"/blog/2018/10/02/adventures-with-infogans-towards-generative-models-of-biological-images/","publishdate":"2018-10-02T09:00:46Z","relpermalink":"/blog/2018/10/02/adventures-with-infogans-towards-generative-models-of-biological-images/","section":"post","summary":"I recently began an AI Residency at Google, which I am enjoying a great deal. I have been experimenting with deep-learning approaches for a few years now, but am excited to immerse myself in this world over the coming year.","tags":null,"title":"Adventures with InfoGANs: towards generative models of biological images (part 1)","type":"post"},{"authors":null,"categories":["Parasites"],"content":"Sometimes in science you come across things that are definitely interesting, and useful, but which you donât have time to write up properly for one reason or another. Iâm going to try to get into the habit of sharing these as blog-posts rather than letting them disappear. Here is one such story.\n Not long ago I was searching for orthologs of a malaria gene of interest on the NCBI non-redundant database, which allows one to search across the entire (sequenced) tree of life. Here is a recreation of what I saw:\nI was surprised to see that nestled among the Plasmodium species was a sequence from a species calledÂ Piliocolobus tephrosceles.\nA web search revealed this to be the linnaean name for the Ugandan red colobus monkey. Odd that this monkey should have a gene so similar to one from a parasite, eh? But there are some weird misannotations on NCBI. However a bit later I saw the same thing happen again with another gene, and thought something must be going on. I tried more malaria genes and found I could almost always find a strong match in the colobus assembly.\nI navigated through NCBI to find some more about this particular monkey.\nThe pageÂ tells us that this monkey from which this genome was sequenced was found here, in the depths of Kibale National Park (it was sequenced for a University of Oregon genome study, in prep.):\nIt also tells us that the sequence came from whole blood. This methodology seemed to be consistent with researchers serendipitously acquiring sequence from a blood-borne parasite in the process of sequencing the monkey genome.\nJust how much of this genome is there in the colobus sample? I downloaded the assembly to find out. The assembly was broken up into 47,644 contigs. My hypothesis was that some of these represented monkey sequence and others represented this sequence of a malaria-like parasite. I calculated the GC content of each contig and plotted a distribution:\nPlasmodium spp. have a much lower GC-content than mammalian species, and from this it looks like whatever species we have here shows this same bias. Just to be sure I also searched each âcolobusâ contig with Diamond (a faster Blast-like tool) against all protein sequences of the rhesus macaque and ofÂ P. vivax. If a contig had a significantly higher score in P. vivax than rhesus it was assigned to that species and vice versa. Overlaying this data was pretty compelling:\nI decided that by taking contigs which were either significantly better matches to P. vivax, or alternatively had a GC content below 24%, I would get a genome which was almost entirely this intriguing species. This gave me 13,460 contigs representing about 30 Mbp of sequence (Plasmodium genomes are 20-30 Mbp so this could potentially be a genomeâs worth â although I donât always get BLAST matches, so I suspect it is somewhat less). I also got in touch with the person named in the NCBI accession to see if they were already investigating these:\nhey @theosanderson not specifically on the hepatocystis seqs in the assembly, though collaborators in our group have done some interesting work on hepatocystis in red colobus themselves https://t.co/yLs6ycTYrv  â Noah Simons (@noahdsimons) April 5, 2018  My home institute has released a rather neat web tool called Companion, which allows you to upload a series of genomic contigs and have them annotated with reference to a known genome using a whole pipeline of analysis. (Unfortunately it only accepts up to 3,000 sequences. But you can download it as a Docker container to circumvent that restriction).\nHere are the results from its run on these sequences. Companion identifies \u0026gt;2000 genes, including such favourites as circumsporozoite protein, GAP50, PTEX88 and the SERAs. It nicely annotates a pseudochromosome-based version of the genome (although Iâm not sure itâs taking full advantage of the synteny at the moment).\nSo what is this mysterious species?\nIt clearly isnât an already sequenced Plasmodium species. A bit of googling suggested to me that it might be some species of Hepatocystis, which are known to infect red Colobus. Hepatocystis seems in some ways to be an unnecessary genus, since the latest phylogenies show that evolutionarily it lies nested withinÂ Plasmodium, being more closely relatedÂ to mammalian Plasmodium species than is the avian malaria parasiteÂ Plasmodium gallinaceum. But there are reportedly important differences of approach between the groups â hepatocystis seems to lack the asexual cycle, with replication occurring only in the liver. One might hypothesise that this would lead to substantial loss of intra-erythrocytic genes. Also these beasts are transmitted by midges rather than mosquitoes (that data the result of a decadeâlong search). There are no other genome-scale sequencing datasets available for hepatocystis.\nI searched GenBank for targeted hepatocystis sequences, and found a few, including the caseinolytic protease C gene which has been sequenced from numerous batÂ isolates. I found the matching sequences for these in the Colobus assembly and then Blasted those sequences back against GenBank to recover a set of sequences to analyse. Constructing a tree with Phylogeny.fr seemed to demonstrate clearly that this is some species of hepatocystis:\nThe closest relative found here is from a Cynopterus brachyotis bat from SingaporeÂ â bats seem to pick up everything!\nThis is about as far as Iâve got with this. Some thoughts at this point:\n If you are interested in what a specific gene looks like in hepatocystis it is likely that you can find at least part of it in these colobus contigs to compare to. It is very easy to run a BLAST search at NCBI to check. Early data-release is awesome! Parasitologists will really benefit from the University of Oregon primate researchers making this data available. Someone should really see if we can get a really decent genome from these short read sequences. The library was prepared with Chromium technology and assembled with SuperNova, a 10X assembler. Is it possible these methods are optimised for diploid sequences and that assembling the raw data might enable a better parasite assembly? Or maybe the current assemblyÂ is pretty good â apart from the gaps â and missing _PlasmodiumÂ _genes are truly missing due to the differences in the hepatocystis lifecycle? The depositors of the assembly might wish to partition it into its monkey and hepatocystis portions as I have above, lest a lot of parasite researchers are going to get confused when they find their parasite to be so closely related to a monkey ð Happy to share my assignments! ","date":1524505150,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1524505150,"objectID":"9e0f63d9087ef4b2bac4c9b1c52b544d","permalink":"/blog/2018/04/23/how-i-stumbled-upon-a-novel-genome-for-a-malaria-like-parasite-of-apes/","publishdate":"2018-04-23T17:39:10Z","relpermalink":"/blog/2018/04/23/how-i-stumbled-upon-a-novel-genome-for-a-malaria-like-parasite-of-apes/","section":"post","summary":"Sometimes in science you come across things that are definitely interesting, and useful, but which you donât have time to write up properly for one reason or another. Iâm going to try to get into the habit of sharing these as blog-posts rather than letting them disappear. Here is one such story.\n Not long ago I was searching for orthologs of a malaria gene of interest on the NCBI non-redundant database, which allows one to search across the entire (sequenced) tree of life. Here is a recreation of what I saw:\nI was surprised to see that nestled among the Plasmodium species was a sequence from a species calledÂ Piliocolobus tephrosceles.\n","tags":null,"title":"How I stumbled upon a novel genome for a malaria-like parasite of primates","type":"post"},{"authors":null,"categories":["Automation"],"content":"**TL;DR:Â **Some 3D-printing hackery can create an automated microscope stage from a manual stage for ~0.5% of the cost from the manufacturer.\n I have always wanted access to a microscope with an automated stage. The ability to scan an entire slide/plate for a cell of interest seems to unlock a wealth of new possibilities.\nSadly, these systems cost quite a bit. The lab I work in now has a Leica DMi8 microscope with automated movement in Z. But XY movement is (on our model) still manual. It is possible to purchase an automated XY stage for this microscope, but the list-price quote is around Â£12,000 (including stage, and control hardware and software).\nIâm not going to argue that this price is unreasonable. I am sure that the manufacturers of scientific equipment spend a lot of time and money innovating, and that money has to be made back by selling devices which have relatively small production runs. Nevertheless, the result is that the costs of kit that makes it to market are fairly staggering â and this prevents someone like me from being able to play around with an automated stage.\nBut I still wanted to experiment with an automated stage! So I wondered how easy this would be to do myself. After all, we have a manual stage, and we move it by rotating two knobs. Couldnât I just get motors to turn those instead of doing it with my hand?\nAs I thought this through further I realised it was slightly complicated than this. Firstly, the knobs are co-axial, making them rather harder to deal with than would be two separate shafts. And secondly, as you rotate the X-knob, the shaft moves in X.\nSo the motors need to be able to move with it. But they also need to be to rotate and exert a twisting force on the knob â so they need to move linearly but be locked in one orientation.\nHardware: 3D printed pieces, 2 stepper motors and a RAMPS controller\nI made a quick design in OpenSCAD\nBasically the first knob,which controls movement in Y, is simply connected to the mechanism by a (red) sleeve which connects to a motor below. The knob above, which controls movement in X, is placed inside a (blue) sleeve which covers it in a gear. That gear is turned by a (turquoise) gear turned by a second motor. Both motors are mounted on a (transparent) piece which also connects them to a LM6LUU linear bearing which allows them to slide but keeps their orientation constant.\nI printed out these 3 pieces â then tweaked the dimensions a little to be more snug on the knobs and printed them again. The final STL files, and the SCAD file that generated them are available on Thingiverse.\nTo control it I connected the steppers to a trusty RAMPS 3D printer controller. These cost Â£30 with a screen and a rocker controller (the Leica hardware to control a stage is ~Â£3k). Since the 3D printer controller is also all set up to control the temperature of a hot-end and a heated bed, if you want to add warm stage down the line this might be ideal.\nInitial tests controlling the position using the system using the RAMPS controller went well, and let me calibrate the number of steps per micrometer.\n\nSoftware: MicroManager Regrettably, the Leica software isnât going to allow you to easily hook it up to an Arduino-based controller. But, as ever, open-source software comes to the rescue. Micro-Manager is a very advanced ImageJ plugin that can connect to the Leica camera, and to the microscope itself to control filter cube positions, Z-focusing, etc.\nDonât expect quite the user-friendliness of Leica software from Micro-Manager, butÂ _doÂ _expect a wealth of packages to perform common operations in automated-microscopy (Leica charges ~Â£2.5k for the software to revisit a position multiple times â which was included in the quote given above).\nTheoretically, MicroManager even allows you to control XY position using a RAMPS controller â someone has already written a package for exactly this board. This step, which should have been trivial, was actually the most complicated. The device adapter is designed to ask the RAMPS controller for its version, and somehow I could never make my board submit a response that the software was happy with. I had to download the MicroManager source and remove the code that checked the version. Successfully setting up the build environment for Windows took an age. Do get in touch if you have a similar project and want the DLL I built [update: DLL here, I offer no guarantees at all that it will work. This is an x64 build which will only work with a recent nightly build] [update 2: Nikita Vladimirov has followed up on this and released the changes he had to make to MicroManager]. Anyway, to cut a long story short I got MicroManager to talk to the RAMPS board successfully.\nTesting by making a 100X oil immersion slide scanner Now to put it into practice.\nI wrote a Beanshell script to scan a slide in X and Y and capture images. In this case I captured images in a grid 40 microscope images wide by 30 microscope images high, for a total of 1200 images.\n\nThis took a few minutes â try doing that by hand.. Then I stitched them together with the MIST plugin. The result is a 27,000 x 12,000 pixel image, featuring a whole lot of red blood cells. You can zoom in on the version below. This was taken with a 100X oil immersion objective, at which magnification the smallest motion of the stage is a substantial fraction of the image, but still allows enough overlap for stitching.\n\n Fun! Still a bit more experimenting to do, but Iâm hoping to get this acquiring tagged proteins from 96-well plates.\nCaveat for anyone who tries to implement this: obviously be very careful not to create significant non-twisting forces on the coaxial knobs â you donât want to damage your stage and ruin the alignment.\n","date":1517495441,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1517495441,"objectID":"fb39970aae35f35c64b930b9a90207a0","permalink":"/blog/2018/02/01/save-99-5-upgrading-a-manual-microscope-with-an-automated-stage-for-60/","publishdate":"2018-02-01T14:30:41Z","relpermalink":"/blog/2018/02/01/save-99-5-upgrading-a-manual-microscope-with-an-automated-stage-for-60/","section":"post","summary":"**TL;DR:Â **Some 3D-printing hackery can create an automated microscope stage from a manual stage for ~0.5% of the cost from the manufacturer.\n I have always wanted access to a microscope with an automated stage.","tags":null,"title":"Saving 99.5%: automating a manual microscope with a 3D printed adapter","type":"post"},{"authors":null,"categories":["Uncategorized"],"content":"Thesis PDF\n","date":1511614447,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1511614447,"objectID":"85199428e44e459f11903457921123bd","permalink":"/blog/2017/11/25/hello-world/","publishdate":"2017-11-25T12:54:07Z","relpermalink":"/blog/2017/11/25/hello-world/","section":"post","summary":"Thesis PDF","tags":null,"title":"New beginnings","type":"post"},{"authors":["Ellen Bushell","Ana Rita Gomes","Theo Sanderson","Burcu Anar","Gareth Girling","Colin Herd","Tom Metcalf","Katarzyna Modrzynska","Frank Schwach","Rowena E. Martin","Michael W. Mather","Geoffrey I. McFadden","Leopold Parts","Gavin G. Rutledge","Akhil B. Vaidya","Kai Wengelnik","Julian C. Rayner","Oliver Billker"],"categories":null,"content":"","date":1498867200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1498867200,"objectID":"03652ed8297759f540c4706503640f92","permalink":"/publication/2017-functional_profiling/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/2017-functional_profiling/","section":"publication","summary":"In this work we conducted the first genome-scale genetic screen in a malaria parasite. We found that malaria parasites have require a higher proportion of their genome for normal growth compared to any other eukaryote previously screened. I led the analysis portion of this work, including building the [dashboard](https://plasmogem.sanger.ac.uk/phenotypes) used by the community to access our phenotype data.","tags":[],"title":"Functional profiling of a Plasmodium genome reveals an abundance of essential genes","type":"publication"},{"authors":["Theo Sanderson","Julian C. Rayner"],"categories":null,"content":"","date":1498867200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1498867200,"objectID":"8650812bf60f4c622e35760e0bedf18a","permalink":"/publication/2017-phenoplasm/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/2017-phenoplasm/","section":"publication","summary":"[PhenoPlasm](http://www.phenoplasm.org) is a database of all disruption phenotypes in malaria parasites. I conceived of, designed, created and continue to curate the database.","tags":[],"title":"PhenoPlasm: a database of disruption phenotypes for malaria parasite genes","type":"publication"},{"authors":null,"categories":["Non-bio"],"content":"The houses of parliament in the UK host a website of petitions. When a particularly popular petition is trending it can be addictive to refresh the page and watch the numbers going up behind your eyes. But of course what one really wants is a graph.\nSo I built this tool which regularly queries the parliament API and stores historical petition signatures in a database which it uses to draw graphs.\n","date":1484523958,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1484523958,"objectID":"47627a0ac7e46f649c3903b03d5e23a0","permalink":"/blog/2017/01/15/petition-grapher/","publishdate":"2017-01-15T23:45:58Z","relpermalink":"/blog/2017/01/15/petition-grapher/","section":"post","summary":"The houses of parliament in the UK host a website of petitions. When a particularly popular petition is trending it can be addictive to refresh the page and watch the numbers going up behind your eyes.","tags":null,"title":"Petition grapher","type":"post"},{"authors":["Theo Sanderson"],"categories":null,"content":"","date":1483228800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1483228800,"objectID":"ce30131df5eb9ef0ac2a376969ee6387","permalink":"/publication/sanderson-2017-open/","publishdate":"2021-01-21T16:48:35.971426Z","relpermalink":"/publication/sanderson-2017-open/","section":"publication","summary":"","tags":null,"title":"Open hardware for random access plate storage","type":"publication"},{"authors":["Theo Sanderson","Julian C Rayner"],"categories":null,"content":"","date":1483228800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1483228800,"objectID":"dc2368147cfbda996fb2ccce87900218","permalink":"/publication/sanderson-2017-plasmotron/","publishdate":"2021-01-21T16:48:35.957463Z","relpermalink":"/publication/sanderson-2017-plasmotron/","section":"publication","summary":"","tags":null,"title":"PlasmoTron: an open-source platform for automated culture of malaria parasites","type":"publication"},{"authors":["Leyla Y Bustamante","Gareth T Powell","Yen-Chun Lin","Michael D Macklin","Nadia Cross","Alison Kemp","Paula Cawkill","Theo Sanderson","Cecile Crosnier","Nicole Muller-Sienerth"," others"],"categories":null,"content":"","date":1483228800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1483228800,"objectID":"aac44d4951609d43e369dcd2407ccd05","permalink":"/publication/bustamante-2017-synergistic/","publishdate":"2021-01-21T16:48:35.956466Z","relpermalink":"/publication/bustamante-2017-synergistic/","section":"publication","summary":"","tags":null,"title":"Synergistic malaria vaccine combinations identified by systematic antigen screening","type":"publication"},{"authors":null,"categories":null,"content":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"e8f8d235e8e7f2efd912bfe865363fc3","permalink":"/project/example/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/example/","section":"project","summary":"An example of using the in-built project page.","tags":["Deep Learning"],"title":"Example Project","type":"project"},{"authors":["Theo Sanderson"],"categories":null,"content":"","date":1420070400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1420070400,"objectID":"a3de73b9a0b8feafbff6b3914534569f","permalink":"/publication/sanderson-2015-investigating/","publishdate":"2021-01-21T16:48:35.955468Z","relpermalink":"/publication/sanderson-2015-investigating/","section":"publication","summary":"","tags":null,"title":"Investigating the Plasmodium invadome with high-throughput reverse genetics","type":"publication"},{"authors":["Miguel M Pinheiro","Md Atique Ahmed","Scott B Millar","Theo Sanderson","Thomas D Otto","Woon Chan Lu","Sanjeev Krishna","Julian C Rayner","Janet Cox-Singh"],"categories":null,"content":"","date":1420070400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1420070400,"objectID":"ebc973a0e90cf444dbcc3211d47c1010","permalink":"/publication/pinheiro-2015-plasmodium/","publishdate":"2021-01-21T16:48:35.87903Z","relpermalink":"/publication/pinheiro-2015-plasmodium/","section":"publication","summary":"","tags":null,"title":"Plasmodium knowlesi genome sequences from clinical isolates reveal extensive genomic dimorphism","type":"publication"},{"authors":["Benjamin Reeve","Theo Sanderson","Tom Ellis","Paul Freemont"],"categories":null,"content":"","date":1388534400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1388534400,"objectID":"b99aabc3c0cb94fbee756e7f55bcadfc","permalink":"/publication/reeve-2014-synthetic/","publishdate":"2021-01-21T16:48:35.878058Z","relpermalink":"/publication/reeve-2014-synthetic/","section":"publication","summary":"","tags":null,"title":"How synthetic biology will reconsider natural bioluminescence and its applications","type":"publication"},{"authors":null,"categories":["Sci-comm"],"content":"When Randall Monroe released the amazing Up-Goer Five comic, I was inspired to hack together a customised editor so that I could explain my own research in the limited vocabulary of the thousand most common words.\nFor me the most exciting bit about this was that I got an email from Mr. xkcd himself. It also became a bit of a science-communication craze. A lot of scientists got in on the action (some kind people have made a collection here).\nThe editor has featured in The Guardian (and again). More recently itâs even been used for conference sessions, which are pretty fantastic. (The 9th talk in that playlist is particularly excellent). Itâs also quite popular as a science communication training exercise, although it goes without saying that no-one is suggesting that this is the best way to communicate.\n","date":1358281809,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1358281809,"objectID":"bb18ad393cc780386c4d972d90224af2","permalink":"/blog/2013/01/15/the-up-goer-five-text-editor/","publishdate":"2013-01-15T20:30:09Z","relpermalink":"/blog/2013/01/15/the-up-goer-five-text-editor/","section":"post","summary":"When Randall Monroe released the amazing Up-Goer Five comic, I was inspired to hack together a customised editor so that I could explain my own research in the limited vocabulary of the thousand most common words.","tags":null,"title":"The Up-Goer Five Text Editor","type":"post"},{"authors":null,"categories":["Projects"],"content":"The international genetic engineered machine competition (iGEM) was my first taste of proper experimental science, and I still have a fondness for synthetic biology. I was part of the Cambridge Team for 2010. This was an exciting team project where we got to define our own genetic engineering project and work on it over a summer.\nWe focused on bioluminescence, building modular genetic components (BioBricks) from firefly luciferase, in a number of colours, and also from the bacterium Vibrio fischeri. The exciting thing about the bacterial luciferase is that this permits âautoluminescenceâ, i.e. the bacteria produce light without adding any other chemicals. We exploited this to light ourselves in the photo below.\nIn the project we achieved a Gold Medal, were finalists in the competition and won the prize for Best Wiki, which I designed. As part of the project I built BioBrick2GenBank, a small tool which converts BioBricks to GenBank format for editing in standard cloning software. This has been used \u0026gt;350,000 times to date.\nOur BioBricks have been used by a number of future teams, including by a team from Peking, who used this part in one bacterium, combined with a light sensitive-system in bacteria in a separate tube, to allow cell-cell communication!\nGibson assembly\nWe were also early users of the revolutionary Gibson Assembly protocol, and I penned the lyrics to the embarassing music-video we made to promote it, earning us the (dubious?) distinction of a Craig Venter tweet.\nMedia\nOn the back of this project I was quoted inÂ New Scientist, and later by the BBC.\nBook chapter\nBen Reeve and I later wrote aÂ chapter about the application of bioluminescence in synthetic biology.\n","date":1281900784,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1281900784,"objectID":"b545dbfaa7f464ad85232be9938dae87","permalink":"/blog/2010/08/15/igem/","publishdate":"2010-08-15T19:33:04Z","relpermalink":"/blog/2010/08/15/igem/","section":"post","summary":"The international genetic engineered machine competition (iGEM) was my first taste of proper experimental science, and I still have a fondness for synthetic biology. I was part of the Cambridge Team for 2010.","tags":null,"title":"iGEM","type":"post"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"5a3203ae0b543fa13e16b6757e5f2a48","permalink":"/medialist/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/medialist/","section":"","summary":"","tags":null,"title":"","type":"widget_page"},{"authors":null,"categories":null,"content":"I have reviewed for journals including:\n JAMA Nature Communications  ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"832893d512e4929e92c510d2d3bdb772","permalink":"/reviewing/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/reviewing/","section":"","summary":"I have reviewed for journals including:\n JAMA Nature Communications  ","tags":null,"title":"","type":"page"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"b2e1e682ded2cf71d25fa57af0bd1fe8","permalink":"/media/bla/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/media/bla/","section":"media","summary":"","tags":null,"title":"BBC article","type":"media"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"32f84de128d56f5adb1ede3e5f694c7c","permalink":"/media/bla2/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/media/bla2/","section":"media","summary":"","tags":null,"title":"BBC article 2","type":"media"},{"authors":[],"categories":null,"content":"The problem ``It has not escaped our notice that the specific pairing we have postulated immediately suggests a possible copying mechanism for the genetic material.'' Thus Watson and Crick concluded their short article revealing the structure of DNA in 1953. In writing this they were part of a scientific tradition that is alive and well to this day, the fear that others may get the credit for trivial extensions of one\u0026rsquo;s own hard work.\nDespite huge changes in the landscape of scientific research since, this fear is as alive as ever. And in many circumstances, it may be justified. Scientists applying for jobs and funding are assessed on their publication records, and publications, especially in \u0026ldquo;top\u0026rdquo; journals often rely on narratives and mechanisms, rather than raw data.\nYet disseminating data by waiting for publication in journals, or even for the writing of narrative manuscripts would, and does, drastically reduce scientific progress. An especially dramatic example of this was the release of the first SARS-CoV2 genome on a Discourse group on January 10 by Yong-Zhen Zhang, via Eddie Holmes. This genome set in train the development of PCR tests and vaccines (Moderna\u0026rsquo;s had been designed just two days later). Each day of delay in posting this sequence would have led at minimum to tens of thousands of additional lives lost, considering vaccination alone.\nIn many ways the pandemic has brought out the best in the scientific community, with many sharing data in real time on Twitter, and elsewhere, without worrying too much about being \u0026ldquo;scooped\u0026rdquo;. A shining light has been the sharing of sequence data, deposited on the GISAID database, and made explorable in real time by initiatives such as Nextstrain.\nBut this data sharing has not always been completely smooth. Sometimes those who have done the hard, expensive, work required to generate these sequence data have complained that others have published relatively trivial analyses of these data without involving these originators.\nThese complainants have a point. The GISAID terms and conditions, accepted by anyone in order to access the data, require acknowledgement of the originating laboratories in any analyses of their data. They also require \u0026lsquo;best efforts\u0026rsquo; be made to collaborate with these laboratories, though the FAQ explicitly states that permission from the originating laboratories is not required for publications.\nFundamentally, the argument that many critics are making is that the originators of the data should have the right to make the first narrative descriptions of the events that these data describe: the emergence of a particular variant, its spread in a new country. I suspect that at the root of this argument is a valid fear, that more prestige and recognition may be associated with the statistical description.\nBut what\u0026rsquo;s the point of sharing data in real time on a platform like GISAID? Ultimately it has to be to allow others to analyse it. And those analyses are not of any use unless they are communicated. And the traditional way in which scientific analyses are communicated is by publishing them in journals (I think more efficient alternatives may exist, but this is the current system).\nThe use of GISAID requires acknowledgements, which at least some of these criticised papers complied wtih, providing a table of all the laboratories contributing sequences. But this wasn\u0026rsquo;t enough to assuage the concerns. Because being listed in the acknowledgements of a paper describing an important phenomenon doesn\u0026rsquo;t confer the same prestige as having written that paper. Fundamentally this is the problem. Someone can generate the data needed to understand a key scientific issue, deposit it, and not get the credit for the insights it leads to.\nA remedy? How can we incentivise scientists to create and deposit valuable data? In my view by recording the use of that data, and giving them credit. When another group publishes the first analysis of a set of valuable data, their paper will accrue citations. I think that isn\u0026rsquo;t in itself a problem, and isn\u0026rsquo;t really what causes the resentment. The problem is that those citations, valuable scientific prestige, occur at the expense of the originators of the data.\nWhat if those citations were transitive \u0026ndash; if they flowed from the analysis paper straight down to the originators of the data? The original researchers would gain kudos from there being more analyses of their data out in the world.\nThis is is in essence the notion of a dependency tree. An analysis of SARS-CoV2 genome sequences has many dependencies: the originators of the sequences, the bioinformatic tools for analysing them. Those dependencies each in turn have their own dependencies (generation of a genome may rely on a sequencing protocols like ARTIC).\nFundamentally, I think that if we recorded these dependencies, we would incentivise a better sort of science. Dependencies are different from citations in that they are not limited in number, do not have to be associated with a particular sentence, and are not limited to pointing to, or featuring in publications.\nImplementation SciDep would be a dependency tree of scientific contributions. It would allow the creation of unique IDs for any object desired:\n Publications Repositories    scratchpad\nProposal: GISAID (and other databases) provide a unique ID (rather like a DOI) for each genome / datapoint. scidep.gisaid.11154 . GISAID mandates that you can use that data, but only if you create an entity for your paper scidep.pubmed.115343 which includes as dependencies each of the genomes you used in your analysis.\nThe supercharged version is that the license requires that you apply the same feature to your paper. If you, or a publisher, want to cite it, they in turn have to create a scidep entity for their publication\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"d347bad1db901b1e371e57bc8b81458d","permalink":"/garden/scidep/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/garden/scidep/","section":"garden","summary":"The problem ``It has not escaped our notice that the specific pairing we have postulated immediately suggests a possible copying mechanism for the genetic material.'' Thus Watson and Crick concluded their short article revealing the structure of DNA in 1953.","tags":null,"title":"Scidep - a dependency tree for scientific discovery","type":"garden"}]